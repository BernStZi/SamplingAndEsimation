%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[10pt]{beamer}
\usepackage{etex}

\usepackage[T1]{fontenc}
\usepackage{textpos} 
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amsfonts,nicefrac,mathabx,amssymb}
 \usepackage[subnum]{cases}
\usepackage{calligra, mathrsfs}
%\usepackage{natbib}
\usepackage{booktabs}
%\bibpunct{(}{)}{;}{a}{,}{,}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{helvet}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow,dcolumn}
\usepackage{ragged2e}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{url}
\usepackage{bibentry}
\usepackage{chngcntr}

\ifx\hypersetup\undefined
  \AtBeginDocument{%
    \hypersetup{unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},backref=false,colorlinks=false}
  }
\else
  \hypersetup{unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},backref=false,colorlinks=false}
\fi

\colorlet{tablesubheadcolor}{gray!25}
\colorlet{tableheadcolor}{gray!40}
\colorlet{tablerowcolor}{gray!15.0}
\usetheme{Gesis}
%\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]%{\hspace*{.2cm}\insertframenumber}
\setbeamerfont{caption}{size=\footnotesize}
\usefonttheme[onlylarge]{structuresmallcapsserif} % alte Schrift


\definecolor{hellgrau}{rgb}   {0.109375,  0.40625,   0.51953125}
\definecolor{dunkelgrau}{rgb} {0.009375,  0.30625,   0.41953125}
\definecolor{dunkelgrau2}{rgb}{0.009375,  0.20625,   0.31953125}
\definecolor{hellbraun}{rgb}  {0.9140625, 0.8984375, 0.8046875}
\definecolor{hellbraun2}{rgb} {.95,       0.9,       0.8}
\definecolor{alertred}{rgb}   {0.8515625, 0.3828125, 0.08984375}
\definecolor{orange}{rgb}{1,0.5,0}


\setbeamercolor{firstsecslide}{fg=white,bg=dunkelgrau}
\setbeamertemplate{blocks}[rounded][shadow=true]

\newcolumntype{d}[1]{D{.}{.}{#1}}

\newcommand{\emphred}[1]{\textcolor{alertred}{#1}}
\newcommand{\emphcol}[1]{\textcolor{dunkelgrau}{\slshape #1}}

\newcommand{\eqname}[1]{\tag*{#1}} %equation title

\newenvironment{frcseries}{\fontfamily{frc}\selectfont}{}
\newcommand{\textfrc}[1]{{\frcseries#1}}
\newcommand{\mathfrc}[1]{\text{\textfrc{#1}}}


\setcounter{tocdepth}{1}
\setbeamercolor*{section in toc}{fg=hellgrau}
\setbeamertemplate{bibliography item}[default]


\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}


\newcommand{\E}[1]{\text{E}\left(#1\right)}
\newcommand{\V}[1]{\text{V}\left(#1\right)}
\newcommand{\Vest}[1]{\widehat{\text{V}}\left(#1\right)}
\newcommand{\MSE}[1]{\text{MSE}\left(#1\right)}
\newcommand{\COV}[2]{\text{COV}\left(#1,\,#2\right)}
\newcommand{\deff}{\ensuremath{\text{\slshape deff}}}
\newcommand{\deffhat}{\ensuremath{\widehat{\text{\slshape deff}}}}
\newcommand{\deffc}{\ensuremath{\text{\slshape deff}_{\text{\slshape c}}}}
\newcommand{\deffhatc}{\ensuremath{\widehat{\text{\slshape deff}}_{\text{\slshape c}}}}
\newcommand{\deffp}{\ensuremath{\text{\slshape deff}_{\text{\slshape p}}}}
\newcommand{\neff}{\ensuremath{n_\text{\slshape eff}}}
\newcommand{\nnet}{\ensuremath{n_\text{\slshape net}}}
\newcommand{\ngross}{\ensuremath{n_\text{\slshape gross}}}
%roman numbers in equation
\newcommand{\RN}[1]{%
  \textup{\uppercase\expandafter{\romannumeral#1}}%
}


\makeatletter

\addtobeamertemplate{frametitle}{}{%
\begin{textblock*}{100mm}(.91\textwidth,-1cm)
\includegraphics[height=1cm,width=2cm]{graphs/logos/GESIS_Logo_kompakt_en.jpg}
\end{textblock*}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
% this default might be overridden by plain title style
 \newcommand\makebeamertitle{\frame{\maketitle}}%
 % (ERT) argument for the TOC
 \AtBeginDocument{%
   \let\origtableofcontents=\tableofcontents
   \def\tableofcontents{\@ifnextchar[{\origtableofcontents}{\gobbletableofcontents}}
   \def\gobbletableofcontents#1{\origtableofcontents}
 }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%\usetheme{Montpellier}%\usetheme{PaloAlto}

\makeatother

\begin{document}
<<setup, include=FALSE>>=
library(knitr)
opts_chunk$set(fig.path='graphs/beamer-',fig.align='center',fig.show='hold',size='footnotesize')
@


\title[Complex Sampling Designs]{4. GESIS Summer School in Survey Methodology
Cologne. Course 16: Sampling, Weighting and Estimation}   
\subtitle{Day 2: Complex Sampling Designs}

\author{Stefan Zins\thanks{\href{mailto:Stefan.Zins@gesis.org}{Stefan.Zins@gesis.org}} and Matthias Sand\thanks{\href{mailto:Matthias.Sand@gesis.org}{Matthias.Sand@gesis.org}}}
\date{Tuesday, August 25, 2015} 

\makebeamertitle

%Picture for cluster sampling

\begin{frame}{Cluster Sampling}
\begin{itemize}
\item[]<1-> Sampling elementary units is often not feasible (e.g. persons or businesses). Maybe there is no uniform sampling frame available to select them from, or it would be costly to do, because the selected elements would scatter to much over the a certain area and travel costs of interviewers would be to high. 

\item[]<2-> Thus, it is very common to select clusters, so called \emph{primary sampling units} (PSU's) that are populated by \emph{secondary sampling units} (SSU's).

\item[]<3-> Cluster sampling makes it still possible to obtain unbiased estimates but it can have a big influence on the variance. 
\end{itemize}

\end{frame}


\begin{frame}{Notation}
\begin{tabular}{rcp{8cm}}
$y_{ki}$      &=&value of the variable of interest for the $k$-th SSU in the $i$-th PSU \\
$N_{\RN{1}}$     &=&number of PSU's in the population \\
$N_i$       &=&number of SSU's in the $i$-th PSU \\
$N$         &=&total number of SSU's in the Population \\
$\mathcal{U}$  &=& set of SSU's in the population \\
$\mathcal{U}_{\RN{1}} $  &=& set of PSU's in the population \\
$\mathcal{U}_i$  &=& set of SSU's in the $i$-th PSU \\
$n_{\RN{1}}$         &=&number of PSU's in the sample \\
$n_i$   &=&number of SSU's in the sample from the $i$-th PSU\\
$\mathfrc{s}_{\RN{1}}$  &=& sample of PSU's \\
$\mathfrc{s}_i$         &=& sample SSU's from the $i$-th PSU \\ 
$p_{\RN{1}}(.)$         &=& sampling design of the PSU's \\
\end{tabular}

\end{frame}

\begin{frame}{Estimation in Case of $p_{\RN{1}}(.)=$ SRS}
All SSU's in the sampled PSU's are surveyed, thus
$$\tau_i=\sum_{k \in \mathcal{U}_i} y_{ki}$$
is known of all selected PSU's.
An unbiased estimator for the population mean is
$$\overline{y}_{\text{SRCS}} = \dfrac{N_{\RN{1}}}{N}  \sum_{i \in  \mathfrc{s}_{\RN{1}}}   \dfrac{\tau_i}{n_{\RN{1}}} $$
\onslide*<1>{with variance
$$\V{\overline{y}}_{\text{SRCS}} = \dfrac{N_{\RN{1}}^2}{N^2}  \left( 1 - \dfrac{n_{\RN{1}}}{N_{\RN{1}}} \right) \dfrac{V^2_{\tau}}{n_{\RN{1}}}\;,$$
where
 $V^2_{\tau} = \dfrac{1}{N_{\RN{1}} - 1} \sum_{i \in \mathcal{U}_{\RN{1}}} \left(\tau_i - \mu_\tau \right)^2$
and
 $\mu_\tau = \sum_{i \in \mathcal{U}_{\RN{1}}} \dfrac{\tau_i}{N_{\RN{1}}}$.
 }
\onslide*<2>{An unbiased variance estimator is
$$\Vest{\overline{y}_{\text{SRCS}}}_{\text{SRS}} = \dfrac{N_{\RN{1}}^2}{N^2} \left( 1 - \dfrac{n_{\RN{1}}}{N_{\RN{1}}} \right) \dfrac{s^2_{\tau}}{n_{\RN{1}}}\;,$$
where 
 $$
 s^2_{\tau} = \dfrac{1}{n_{\RN{1}}-1} \sum_{i \in \mathfrc{s}_{\RN{1}} } \left( \tau_i - \overline{\tau}  \right)^2\;.
 $$
with $\overline{\tau}=\sum_{i \in \mathfrc{s}_{\RN{1}} } \frac{\tau_i}{ n_{\RN{1}} }$. 
}
\end{frame}

\begin{frame}
\frametitle{Simple Cluster Sampling}
\onslide<1->{
<<ExCluSam,echo=FALSE,results='asis'>>=
library(xtable)
clu <- matrix(1:25 ,ncol=5, byrow=T)

clu.  <- cbind(clu,  rowSums(clu))
clu.  <- rbind(clu., colSums(clu.))
clu.  <- rbind(clu., c(apply(clu,2,var),NA))
clu.  <- cbind(clu., c(apply(clu,1,var),NA,var(as.vector(clu) )))
dimnames(clu.) <- list(  c(as.character(c(1:5)),"$\\tau_{.j}$","$V^2_{.j}$")
                       , c(as.character(c(1:5)),"$\\tau_{i.}$","$V^2_{i.}$"))


clu.tab <- xtable(clu., digits = 1, caption = "Two Variations of a Population Composed of 5
clusters of Size 5")
align(clu.tab) <- "r|rrrrr|r|r"
print.xtable(clu.tab,hline.after = c(0,5,6),caption.placement="top", sanitize.text.function = identity)

@
We have homogeneity of means between columns and heterogeneity of means between rows.
}
\onslide<2>{Sample $n=10$ SSU's by
\begin{enumerate}[label=\arabic*)]
\item SRS n=10
\item Simple random cluster sampling $n_{\RN{1}}=2$
\begin{enumerate}[label=\alph*)]
 \item columns
 \item rows
\end{enumerate}
\end{enumerate}
}
\end{frame}

\begin{frame}
	\frametitle{Simple Cluster Sampling}
	 Comparing the mean and variance of $\overline{y}$ and $\overline{y}_{\text{SRCS}}$ after 100,000 samples:
<<ExCluSamSim,each=TRUE,echo=FALSE,results='asis'>>=
set.seed(3456)
R <- 100000  #number samples
n   <- 10
n_I <- 2
N   <- length(clu)

#SRS
y.bar.sim    <- sapply(1:R,function(x){ 
                            c( srs=mean(as.vector(clu)[sample(length(clu),10)])
                              ,srcs.c=mean(clu[,sample(ncol(clu),2)])
                              ,srcs.r=mean(clu[sample(nrow(clu),2),]) )
                           })
#results
OUT           <- apply(y.bar.sim,1,function(x)c(mean=mean(x),var=var(x)))
dimnames(OUT) <- list(   c("mean", "var")
                       , c("SRS","SRCS a", "SRCS b"))

sim.tab <- xtable(OUT, digits = 1, caption = "Results from the Simulation Study")
align(sim.tab ) <- "l|rrr"
print.xtable(sim.tab, hline.after = 0,  caption.placement="top")

@
\onslide<2->{True values:
\begin{tabular}{l c d{1} l}
$\mu $ & =& \Sexpr{mean(clu)} & \\
$\V{\overline{y}}_{\text{SRS}}$ &=& \Sexpr{ (1-n/N)*var(as.vector(clu))/n}	&  SRS \\
$\V{\overline{y}_{\text{SRCS}}}_{\text{SRS}}$  &=& \Sexpr{ ncol(clu)^2/N^2 * (1-n_I/ncol(clu))*var(apply(clu,2,sum))/n_I }   & SRCS  a \\
 $\V{\overline{y}_{\text{SRCS}}}_{\text{SRS}}$ &=& \Sexpr{ nrow(clu)^2/N^2 * (1-n_I/nrow(clu))*var(apply(clu,1,sum))/n_I }   &  SRCS b \\
\end{tabular} \newline
Bias is not an issue, however variance is. 
}
\onslide<3->{\newline
If the cluster where strata, which stratification would you use, columns or rows?}
\onslide<4->{\newline What good is for stratified sampling, i.e. low SSW, is bad of cluster sampling and vice versa.}
\end{frame}

\begin{frame}{Two Stage Sampling}
 \begin{description}
 \item[First  stage] A sample $\mathfrc{s}_{\RN{1}}$ of PSU's is drawn from $\mathcal{U}_{\RN{1}}$ according to some sampling design $p_{\RN{1}}(.)$
 \item[Second stage] For every $i \in \mathfrc{s}_{\RN{1}}$ a sample $\mathfrc{s}_i$ of SSU's is selected from $\mathcal{U}_i$ according to some design $p_i(.|\mathfrc{s}_{\RN{1}})$
 \end{description}
 The resulting sample of SSU's is denote $\mathfrc{s}= \bigcup_{i \in \mathfrc{s}_{\RN{1}}} \mathfrc{s}_i $.
 In general samples $\mathfrc{s}_i$ are selected independently of each other, thus the inclusion probability of a element $k \in \mathcal{U}_i$ is
$$\pi_k=\pi_{\RN{1}i}\pi_{k|i}\;,$$
where $\pi_{\RN{1}i}$ is the probability of selecting the $i$-th PSU and $\pi_{k|i}$  the probability of selecting
the $k$-th SSU in the $i$-th PSU.
\end{frame}


\begin{frame}{Estimation Simple Random Tow Stage Sampling}
Designs $p_{\RN{1}}(.)$ and $p_i(.|\mathfrc{s}_{\RN{1}})$ are both SRS.
Since not all SSU's in the sampled PSU's are surveyed  $\tau_i$ has to be estimated by $\hat{\tau}_i = \frac{N_i}{n_i} \sum_{k \in \mathfrc{s}_i} y_{ki} $.
An unbiased estimator for the population mean is
$$ \overline{y}_{\text{2SRS}} = \dfrac{N_{\RN{1}}}{N}  \sum_{i \in  \mathfrc{s}_{\RN{1}}}   \dfrac{\hat{\tau}_i}{n_{\RN{1}}} $$
\onslide*<2>{with variance
$$
\V{\overline{y}_{\text{2SRS}}}_{\text{SRS}} = \dfrac{1}{N^2}  \left( N_{\RN{1}}^2  \left( 1 - \dfrac{n_{\RN{1}}}{N_{\RN{1}}} \right) \dfrac{V^2_{\tau}}{n_\RN{1}} + \dfrac{N_{\RN{1}}}{n_{\RN{1}}} \sum_{i \in \mathcal{U}_{\RN{1}}} N_i^2 \left( 1 - \dfrac{n_i}{N_i} \right) \dfrac{V_{i}^2}{n_i} \right) \;,
$$
where $V_{i}^2 = \frac{1}{N_i-1} \sum_{k \in \mathcal{U}_i} (y_{ki} - \mu_i )^2$ with $\mu_i = \sum_{k \in \mathcal{U}_i} \dfrac{y_{ki}}{N_i}$.
}\onslide*<3>{An unbiased variance estimator is given by
$$
\Vest{\overline{y}_{\text{2SRS}}}_{\text{SRS}} =  \dfrac{1}{N^2}  \left( N_{\RN{1}}^2  \left( 1 - \dfrac{n_{\RN{1}}}{N_{\RN{1}}} \right) \dfrac{s^2_{\hat{\tau}}}{n_\RN{1}} + \dfrac{N_{\RN{1}}}{n_{\RN{1}}} \sum_{i \in \mathfrc{s}_{i}} N_i^2 \left( 1 - \dfrac{n_i}{N_i} \right) \dfrac{s_{i}^2}{n_I}  \right) \;,
$$
where $s^2_{\hat{\tau}}=\frac{1}{n_{\RN{1}}-1} \sum_{i \in \mathfrc{s}_{\RN{1}} } (\hat{\tau}_i  - \overline{\hat{\tau}} )^2$
with $\overline{\hat{\tau}} = \sum_{i \in \mathfrc{s}_{\RN{1}} }\frac{\hat{\tau}_i}{n_{\RN{1}}}$ and 
$s^2_{i} = \frac{1}{n_{i}-1}  \sum_{k \in \mathfrc{s}_{i} } (y_{ki}  - \overline{y}_i )^2$
with $\overline{y}_i  = \sum_{k \in \mathfrc{s}_{i} } \frac{y_{ki}}{n_i}$.

}
%Note: For $M_i = n_i$ we are back to SRCS.
\end{frame}


\begin{frame}{Unequal Probability Sampling I}
There are good reasons to deviate from the simple selection procedure that gives every unit the same inclusion probability. If good prior information is available its incorporation into the sampling design can dramatically improve the efficiency of an estimator.
\begin{itemize}
 \item An optimal allocation would be favorable to a proportional allocation.
 \item Selecting the elements proportional to a variable that is correlated to the variable of interest can greatly improve the quality of estimates.
\end{itemize}

There are many techniques (i.e. sampling algorithms) to select elements with unequal probabilities [Till\'e, 2006].
% Some of them have variable sample sizes (e.g. Poisson Sampling), other have but
% 
% Possion Sampling simple but  
% Systematic Sampling
% Sampford simple not

\end{frame}


\begin{frame}{A Generic Design Based Estimator}
A design unbiased estimator for the total $\tau=\sum_{k \in \mathcal{U}} y_k$ is given by
\begin{gather*}
 \hat{\tau}_{\pi} = \sum_{k \in \mathfrc{s}} \dfrac{y_k}{\pi_k} \;,
\end{gather*}
which is also known as \emph{Horvitz-Thompson} (HT) or $\pi$-estimator.
%Assuming a design with strictly positive second order inclusion probabilities
\onslide*<2>{
The variance of $ \hat{\tau}_{\pi} $ is 
\begin{align*}
 \V{ \hat{\tau}_{\pi}} = \sum_{k \in \mathcal{U}} \sum_{l \in \mathcal{U}} \left( \pi_{kl} - \pi_k \pi_l \right)
\dfrac{y_k}{\pi_k}\dfrac{y_l}{\pi_l} \;,
\end{align*}
which can be estimated by
\begin{align*}
 \Vest{ \hat{\tau}_{\pi}}_1 = \sum_{k \in \mathfrc{s}} \sum_{l \in \mathfrc{s}} \dfrac{\left( \pi_{kl} - \pi_k \pi_l \right)}{\pi_{kl}} \dfrac{y_k}{\pi_k}\dfrac{y_l}{\pi_l} \;.
\end{align*}
}\onslide*<3->{
For a fixed size design we may write the variance of $\hat{\tau}_{\pi}$ as
\begin{align*}
 \V{ \hat{\tau}_{\pi}} = - \dfrac{1}{2} \sum_{k \in \mathcal{U}} \sum_{l \in \mathcal{U}} \left( \pi_{kl} - \pi_k \pi_l \right) \left(\dfrac{y_k}{\pi_k} - \dfrac{y_l}{\pi_l}\right)^2 \;,
\end{align*}
which can be estimated by
\begin{align*}
 \Vest{ \hat{\tau}_{\pi}}_2 = - \dfrac{1}{2} \sum_{k \in \mathfrc{s}} \sum_{l \in \mathfrc{s}} \dfrac{\left( \pi_{kl} - \pi_k \pi_l \right)}{\pi_{kl}} \left(\dfrac{y_k}{\pi_k} - \dfrac{y_l}{\pi_l}\right)^2 \;.
\end{align*}
}
\onslide*<4>{Provided that $\pi_{kl} > 0$ for all $k \neq l \in \mathcal{U}$ both variance estimators are unbiased. Nevertheless both variance estimators can become negative!}
\end{frame}


\begin{frame}{Unequal Probability Sampling II}
If there is some prior information available in the form of a variable $\mathcal{X} =  \{ x_1{,}x_2{,}\,\ldots{,}\,x_k{,}\,\ldots{,}\,x_N \}$ which is correlated to our variable interest $\mathcal{Y}$ we can select elements proportional to it

$$\nu_k = \dfrac{x_k}{\sum_{k \in \mathcal{U}} x_k} n \;.$$
Unequal inclusion probabilities can reduce the variance of an estimator, \emph{if} they are related to the variable of interest. We may have $\nu_k=\pi_k$ but in general $\nu_k$ can be greater than 1. \newline

For instance, to estimate the sales in an industry, sampling companies or business with equal probabilities might be bad idea. It would be better to sample companies proportional to a variable that is related to their sales, say their number of employee. That way there is a much higher chance to included the biggest companies into the sample that accumulate the major share of the sales. \newline

Note: In the extreme case if $\pi_k = \alpha y_k$, with  $\alpha \in \mathbb{R}$, for all $k \in \mathcal{U}$ and we have a fixed size design  $\V{ \hat{\tau}_{\pi}}$ would even be zero.

\end{frame}


\begin{frame}{Systematic Sampling with \\ Unequal Inclusion Probabilities}
Again the elements of the population are brought into a specific ordered and $V^i = \sum_{k=1}^i \pi_k$.
~\\[-4cm]
<<UP.SYS,echo=FALSE,fig.height=8,out.width='.95\\linewidth',fig.pos='th',fig.show = 'asis'>>=
  set.seed(43)
  N   <- 15
  n   <- 3
  ip  <- runif(N)
  ip  <- ip/sum(ip)*3
  V   <- cumsum(ip)
  rs  <- unique(ceiling(V))
  #pdf(file=paste0(graphPath,"presentation/presentation.pdf"), width = 10 , height = 10)
  par(mar=c(0, 0, 0, 0), xpd=NA)
   plot(c(0, 3), c(0, 3), type = "n", xlab = "", ylab = "", bty="n", axes=FALSE)
  lines(x=c(0,3),y=c(1.5,1.5),lwd=1.2)
  
  #integers
  arrows(x0=c(0,rs), y=1.5, x1=c(0,rs), y1=1.3, length=0, lwd=2)
    text(x=c(0, rs), y=1.2, labels=c(0,rs), cex=1.2, offset=0)
  
  #cumulated inclusion pobabilities
  arrows(x0=c(0,V) ,y=1.5, x1=c(0,V) , y1=1.6, length=0, lwd=1.5)
  text(x=0, y=1.7, labels=bquote(V^{.(0)}) , pos=1, offset=0, cex=1.2)
 
  for(i in 1:length(ip)){
   expr. <- bquote(V^{.(i)})
   text(x=V[i], y=1.7, labels=expr. ,cex=1.2, pos=1, offset=0)
  }
  
  #The sample 
  #S. <- UPsystematic.(n/N)
  u  <- runif(1)
  a = (c(0, cumsum( ip)) - u)%%1
  S. = as.integer(a[1:N] > a[2:(N + 1)])
  
  s.cod <- u + 0:(floor(max(V))-1)
  s.id <- which(S.==1)
  
  #graphPath1 <- paste0(graphPath,"SYS_coord_start_fixPop.pdf")
  #dev.copy(pdf,file=graphPath1)
  #dev.off()
 
  for(i in 1:length(s.id)){

  #graphPath2 <- paste0(graphPath,"SYS_coord_sample",i,".pdf")

   arrows(x0=s.cod[i] , y0=1.1, x1=s.cod[i], y1=1.5, length=0.1, lwd=1.5)
   if(i==1) text(x=s.cod[i]  , y=1, labels=bquote(lambda[k])  ,  cex=1.2)
   if(i>1)  text(x=s.cod[i]  , y=1, labels=bquote(lambda[k]+.(i-1))  ,  cex=1.2)
     text(x=V[s.id[i]], y=1.7 , labels=bquote(V^{.(s.id[i])}), pos=1, offset=0
          ,cex=1.2, col="firebrick1")
   #dev.copy(pdf,file=graphPath2)
   #dev.off()
  }
  
@
~\\[-4cm]
Systematic selection remains popular because of its simplicity. Also it can easily be applied to the case where an element can be selected more than one time, i.e. $\pi_k \neq \nu_k > 1$. Then we would use $V^i = \sum_{k=1}^i \nu_k$.

\end{frame}


\begin{frame}{A Typical Sample of Persons}{in Germany}
\onslide*<1>{A two-stage Sampling Design:

\begin{description}
\item[First Stage] Municipalities are the PSU's. The sampling design for the PSU's is a stratified design with an allocation proportional to the population within each stratum (not number of PSU's). Within the strata PSU's are sampled proportional to their population size.
\item[Second Stage] Persons are the SSU's. The SSU's are selected form the 	population register of the  municipalities by a simple systematic sample.
\end{description}

}
\onslide*<2>{
\begin{itemize}
\item Very large municipalities, (e.g. Berlin), are selected with certainty, this happens if
$\nu_i = \dfrac{N_i}{N} n_{\RN{1}} > 1$. The integer part of $\nu_i$ indicates how many sampling points are \emph{at least} associated with a municipalities. A sampling point is here a multiplier, indicating how many times $n_i$ SSU's are selected from the $i$-th PSU, where $n_i$ is usually fix for all PSU's.

\item For instance, $\nu_i=3.4$, means that the $i$-th PSU will always be in the sample with at least 3 sampling points, but with a probability of $0.4$ it can be in the sample with 4 sampling points.
\end{itemize}
}

\onslide<3->{Has this design equal inclusion probabilities? \newline}\onslide<4>{Yes, if for each sampling point the same number of SSU's $n_{\ast}$ is sampled. Because 
$$\dfrac{N_i}{N} n_{\RN{1}} \times \dfrac{n_{\ast}}{N_i} = \dfrac{n_{\RN{1}} n_{\ast}}{N} \;.$$
Note that $n_{\RN{1}}$ is not the size of the PSU sample, but the number of sampling points, which can be higher.
}

\end{frame}



%Also the 
\begin{frame}{On Complex Sampling Design}
\begin{itemize}
\item<1|only@1> Selecting PSU's or clusters proportional to some size measure is very common.
This however does not mean that the inclusion probabilities of elementary units are unequal.

\item<2|only@2>  The concept of two-stage designs can also be extended to three, four, or more stages.
The principle of such multi-stage design remains the same, select clusters then select again within clusters.

\item<3|only@3>  There are many ways to optimize the sampling design with respect to one particular goal, i.e. the estimation of a specific statistic. However, it becomes difficult to optimize a design and at the same time retain a balance for a maximum of possible applications, which is a problem when planning a multipurpose survey that has a multitude of variables and covers different topics.
Thus simple design,  such as SRS or StrSRS, are justifiable, as these designs are robust towards any possible analysis of the sample data.

\item<4|only@4>  Multi-stage sampling is usually not a matter of choose but done out of necessity.

\item<5|only@5>  Most importantly, the same design weights ($\pi_k^{-1}$) do \emph{not} imply the same sampling variance. Different designs can be used to select samples with same $\pi_k$'s, however their $\pi_{kl}$'s might be very different and so is their associated sampling variance.

\end{itemize}

\end{frame}

\section{Design Effect}

\begin{frame}\frametitle{The Design Effect}
 The design effect compares strategies, i.e. a combination of a sampling design and an estimator.

	If $p(.)$ is some other design than SRS, however with $\sum_{i=1}^N \pi_k$ equal to the sample size $n$ of the SRS design, then the \emph{design effect} for strategy $(p(.) ,\, \hat{\tau}_{\pi})$ can be defined as
	 $$ \deff(p, \hat{\tau}_{\pi}) = \dfrac{\V{\hat{\tau}_{\pi}}_p}{\V{ \hat{\tau}_{\pi}}_{\text{SRS}}} = 
	  \dfrac{\sum_{k=1}^N \sum_{l=1}^N  \left(\pi_{kl}  - \pi_k \pi_l \right) \dfrac{y_k}{\pi_k}\dfrac{y_l}{\pi_l}}{N^2 \left( 1 - \dfrac{1}{N} \right) \dfrac{V^2}{n} }\;{.} 
	 $$
	The design effect $\deff(p, \hat{\tau}_{\pi})$ expresses how well a design $p(.)$ fares in comparison to reference design SRS.

	\begin{itemize}
		\item $\deff(p, \hat{\tau}_{\pi})$  > 1 precision is lost by not using SRS
		\item $\deff(p, \hat{\tau}_{\pi})$  < 1 precision is gained by not using SRS
	\end{itemize}

\end{frame}


\begin{frame}\frametitle{Design Effect for a Cluster Sample}
  \onslide*<1>{
  Recall from stratified sampling:
  \begin{table}\caption{Population ANOVA}
  \begin{tabular}{l | l | l }
  Source                   & sf    & Sum of Squares  \\
  \hline 
   Between cluster         & $N_{\RN{1}}-1$ & $\text{SSB}  = \sum_{i=1}^{N_{\RN{1}}} N_{i} ( \mu_{i} - \mu )^2$  \\ 
   Within  cluster         & $N-N_{\RN{1}}$ & $\text{SSW}  = \sum_{i=1}^{N_{i}} (N_i - 1) V_{i}^2$  \\
   Total                   & $N-1$ & $\text{SSTO} = (N-1) V^2 $   \\
  \end{tabular}
  \end{table}
  }
  \onslide*<2-3>{
  The homogeneity coefficient 
  $$\delta=1 - \dfrac{SSW(N-N_{\RN{1}})^{-1}}{SSTO (N-1)^{-1} }$$
  is a measure for the similarity of elements within the same cluster.
  }
  \onslide<3->{
  It can be shown that 
  $$\V{ \overline{y}_{\text{SRCS}} }_{\text{SRS}} = 
  \left( 1+ \dfrac{N-N_{\RN{1}}}{N_{\RN{1}}-1}\delta  \right)\V{\overline{y}}_{\text{SRS}} + N_{\RN{1}}^2 \left( 1-\dfrac{n_{\RN{1}}} {N_{\RN{1}}}  \right) \dfrac{\text{COV}}{n_{\RN{1}}} \,,  $$
  where $\text{COV} = \frac{1}{N_{\RN{1}}-1 }\sum_{i \in \mathcal{U}_\RN{1}} (N_i - \frac{N}{N_{\RN{1}}}) N_i \mu_i^2$
  [S\"{a}ndal, 1992, p. 131f.]
  and the design of SRCS is given by
   $$ \deff(SRCS, \hat{\tau}_{\pi}/N) =  1+ \dfrac{ N-N_{\RN{1}} }{ N_{\RN{1}} -1 } \delta  + \dfrac{N\, \text{COV}}{N_{\RN{1}} V^2}\;. 
   $$
   \onslide<4>{
   In case $N_i$ is constant for all cluster COV = 0 and we have
   $$ \deff(SRCS, \hat{\tau}_{\pi}) =  1+ \dfrac{ N-N_{\RN{1}} }{ N_{\RN{1}} -1 } \delta \approx 1 + \left(\dfrac{N}{N_\RN{1}}  - 1 \right)\delta
   $$
   Note that $\delta$ is the adjusted measure of fit for fitting the linear regression of  $\mathcal{Y}$  on $N_{\RN{1}}-1$ dummy variables, indicating cluster membership.
   }
  }
\end{frame}

\begin{frame}[fragile]\frametitle{Design Effect for a Cluster Sample}
<<ExCluSamDeff,echo=FALSE,results='asis',message=FALSE>>=

SSW.byrow <- sum(apply(clu,1,function(x)sum((x-mean(x))^2)))
SSW.bycol <- sum(apply(clu,2,function(x)sum((x-mean(x))^2)))

delta.byrow <- 1 - (SSW.byrow/(length(clu)-nrow(clu)))/var(as.vector(clu))
delta.bycol <- 1 - (SSW.bycol/(length(clu)-ncol(clu)))/var(as.vector(clu))

deff.byrow <- 1 + (length(clu)-nrow(clu))/(nrow(clu)-1)*delta.byrow
deff.bycol <- 1 + (length(clu)-nrow(clu))/(nrow(clu)-1)*delta.bycol

deffs <- matrix(c(delta.bycol, delta.byrow, deff.bycol, deff.byrow),ncol=2,byrow=T)
dimnames(deffs) <- 
 list(c("$\\delta$","$\\deff$"), c("SRCS a", "SRCS b"))

deffs.tab <- xtable(deffs, digits = 5, caption = "Intra-Cluster Homogeneity and Design Effects")
align(deffs.tab ) <- "l|rr"

print.xtable(deffs.tab, hline.after = 0,  caption.placement="top", sanitize.text.function = identity)
print.xtable(clu.tab,hline.after = c(0,5,6),caption.placement="top", sanitize.text.function = identity)

@
\end{frame}

\begin{frame}{Issues associated with Estimation of $\deff$}
  $$ \deff(p(.),\hat{\theta}) = \dfrac{\V{\hat{\theta}}_p}{\V{\hat{\theta}}_{\text{SRS}}} $$
	\begin{itemize}
		\item<1->{ Find suitable estimators for both
		\begin{itemize}
			\item the denominator and
			\item the numerator
		\end{itemize}
		}
		\item<2-> Treat the data as if it had arisen from SRS for estimation of the enumerator (but using available weights).
	\item<3> It is also common to use SRSWR as the reference design, which can simplify the design effect estimation.
	\end{itemize}
	
\end{frame}


\begin{frame}{Variance Estimation}
	\begin{itemize}
		\item Depending on the estimator under study, variance estimation can be cumbersome
		\item The usual (approximate) variance estimation techniques can be applied:
		\begin{itemize}
			\item Linearization
			\item Resampling
		\end{itemize}
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Model-based Approach}
	\begin{itemize}
		\item Again we have $N_{\RN{1}}$ clusters in the population of size $N_i$, $i=1,\dots,N_{\RN{1}}$
		\item Variable $\mathcal{Y}$ is assumed to follow the \emph{common parameter model},
		\begin{eqnarray*}
		  \E{y_{ki}}_{M} &=& \mu \\
		  \notag\V{ y_{ki}}_{M}	&	=	&	\sigma^2 \\
			\COV{y_{ki}}{y_{k'i'}}_{M}	&	=	&
																\begin{cases}%
																	\sigma^2 \rho & \text{for } k\neq k', i = i'
																	\\
																	0							& \text{otherwise.}
																\end{cases}%
		\end{eqnarray*}%
	\end{itemize}
\end{frame}



\begin{frame}{Estimation of $\deff$}{under Cluster Sampling}
\onslide*<1>{
	The considered estimator is $\overline{y}_{w} = \dfrac{\sum_{k \in \mathfrc{s}} w_k y_k}{\sum_{k \in \mathfrc{s}} w_k }$, where $w_k$ is the survey associated with $k$-th element, e.g. 
	$$ w_k =
	\begin{cases}
	\pi_k^{-1} & \text{for}\; k \in \mathfrc{s} \\
	0          & \text{else}
	\end{cases}\,{.}
	$$
	\begin{itemize}
		\item Under the model-based approach, $\deff$ can be displayed as the product of two factors:
		\begin{description}
			\item[$\deffc$] design effect due to clustering
			\item[$\deffp$] design effect due to unequal survey weights
		\end{description}
		\item They indicate loss in precision due to cluster sampling and unequal weights, respectively.
	\end{itemize}
}\onslide*<2>{	Note that under the model-based approach $w_k$ is treated as independent of $y_k$ for all $k \in \mathcal{U}$. Potential gains in precision by using proportional to size design are not considered, quite the contrary, unequal weight will increase the variance of $\overline{y}_{w}$ in this setting.}
\end{frame}


\begin{frame}
	\frametitle{Estimation of $\deffc$}
	\begin{itemize}
		\item Under cluster sampling and two-stage sampling we can use:\\
					\[
						\deffhatc = 1 + \left(\bar{b} - 1\right) \hat{\rho}
					\]%
					with
					\begin{description}
						\item[$\bar{b}$]  as the average cluster size $\frac{N}{N_{\RN{1}}}$ ($\frac{n}{n_{\RN{1}}}$ ) or an estimator for it and 
						\item[$\hat{\rho}$] an appropriate estimator of $\rho$.
					\end{description}
		\item When $w_k$'s vary we have
					\[
					  \deffhatc = 1 + \left(b^{\ast} - 1\right) \hat{\rho}
					\]
					where $b^{\ast}= \frac{ \sum_{i \in \mathfrc{s}_{\RN{1}}} \left( \sum_{k \in \mathfrc{s}_i} w_{k} \right)^2 }{ \sum_{k \in \mathfrc{s} } w_k^2}$ is a kind of weighted average cluster size [Gabler et al., 1999].
	\end{itemize}
	%For two stage cluster 
\end{frame}

\begin{frame}
	\frametitle{Calculation of $\deffp$}
	\begin{itemize}
		\item The design effect due to unequal weights is
					\[
					  \deffp = n \frac{\sum_{k \in \mathfrc{s}} w_k^2} { \left( \sum_{k \in \mathfrc{s}}  w_k \right)^2 }
					\]
		\item Obviously, if $w_k$'s are constant, $\deffp = 1$
	\end{itemize}
\end{frame}

\begin{frame}{Behavior of $\deffc$}
~\\[-1cm]
<<deff-illustration-wire,echo=FALSE,out.width='.8\\linewidth', fig.pos='th', fig.show = 'asis',cache=TRUE>>=
library(lattice)
bbar <- seq(5, 25, by = .5)
rho  <- seq(.02, .2, by=.005)
deff <- function(bbar,rho) 1+ ((bbar-1)*rho)
D <- sapply(bbar, function(x) sapply(rho, function(y) deff(x,y)))
dimnames(D) <- list(rho, bbar)

a.pts <- data.frame(x = c(15,15,15),
                    y = c(.05,.10,.15),
                    z = NA)
a.pts$z <- 1 + ((a.pts$x-1)*a.pts$y)
a <- sort(c(1:6,a.pts$z))

b.pts <- data.frame(x = c(20,20,20),
                    y = c(.05,.10,.15),
                    z = NA)
b.pts$z <- 1 + ((b.pts$x-1)*b.pts$y)
b <- sort(c(1:6,b.pts$z))

f <- unique(sort(c(a,b)))
cols <-  rep("black",length(f))
cols[f%in%a.pts$z] <- "red"
cols[f%in%b.pts$z] <- "green"
cols <- cols[-1]

deffTildeBbarRho <- 
wireframe(D ~ rep(bbar,each=length(rho)) + rep(rho,length(bbar)),
          drape = TRUE,
          at = seq(1,6,by=.5),
          colorkey = TRUE,
          col.regions = c("blue2","grey70"),
          alpha.regions = .5,
          xlab = expression(bar(b)),
          ylab = expression(rho),
          zlab = expression(Deff[c]),
          default.scales = list(arrows = FALSE,
                                x = list(at = c(seq(5,25,by=5),max(bbar))),
                                y = list(at = c(seq(.05,max(rho),by=.05),max(rho))),
                                z = list(at = f, col = cols)),
          a.pts = a.pts,
          b.pts = b.pts,
          screen =list(x=-50,y=55,z=35),
          panel.3d.wireframe = function(x,y,z,
                                        xlim, ylim, zlim,
                                        xlim.scaled, ylim.scaled, zlim.scaled,
                                        a.pts, b.pts, ...){

                                a.xx <- ((a.pts$x -min(bbar))/ (max(bbar)-min(bbar)))-.5
                                a.yy <- ((a.pts$y -min(rho))/ (max(rho)-min(rho)))-.5
                                a.zz <- ((a.pts$z -min(D))/ (max(D)-min(D)))-.5

                                b.xx <- ((b.pts$x -min(bbar))/ (max(bbar)-min(bbar)))-.5
                                b.yy <- ((b.pts$y -min(rho))/ (max(rho)-min(rho)))-.5
                                b.zz <- ((b.pts$z -min(D))/ (max(D)-min(D)))-.5

                                panel.3dscatter(x = a.xx, y = a.yy, z = a.zz,
                                                xlim = xlim,
                                                ylim = ylim,
                                                zlim = zlim,
                                                xlim.scaled = xlim.scaled,
                                                ylim.scaled = ylim.scaled,
                                                zlim.scaled = zlim.scaled,
                                                type = "h", pch = 0, lwd = 5, col = "red",...)

                                panel.3dscatter(x = b.xx, y = b.yy, z = b.zz,
                                                xlim = xlim,
                                                ylim = ylim,
                                                zlim = zlim,
                                                xlim.scaled = xlim.scaled,
                                                ylim.scaled = ylim.scaled,
                                                zlim.scaled = zlim.scaled,
                                                type = "h", pch = 0, lwd = 5, col = "green",...)

                                panel.3dwire(x,y,z,
                                             xlim = xlim,
                                             ylim = ylim,
                                             zlim = zlim,
                                             xlim.scaled = xlim.scaled,
                                             ylim.scaled = ylim.scaled,
                                             zlim.scaled = zlim.scaled,
                                             lwd = 0.25,...)

                                for(i in 1:nrow(a.pts)){
                                  panel.3dscatter(x = c(a.xx[i],-.5,-.5),
                                                  y = c(a.yy[i],a.yy[i],.5),
                                                  z = c(a.zz[i],a.zz[i],a.zz[i]),
                                  xlim = xlim,
                                  ylim = ylim,
                                  zlim = zlim,
                                  xlim.scaled = xlim.scaled,
                                  ylim.scaled = ylim.scaled,
                                  zlim.scaled = zlim.scaled,
                                  pch = 2, col = "red", lwd = 4, type="l",...)}

                                for(i in 1:nrow(b.pts)){
                                  panel.3dscatter(x = c(b.xx[i],-.5,-.5),
                                                  y = c(b.yy[i],b.yy[i],.5),
                                                  z = c(b.zz[i],b.zz[i],b.zz[i]),
                                  xlim = xlim,
                                  ylim = ylim,
                                  zlim = zlim,
                                  xlim.scaled = xlim.scaled,
                                  ylim.scaled = ylim.scaled,
                                  zlim.scaled = zlim.scaled,
                                  pch = 2, col = "green", lwd = 4, type="l",...)}
                               })

print(deffTildeBbarRho)
@
\end{frame}
%' 
%' 

\begin{frame}{An Estimators of $\rho$}
\onslide<1->{
  There are many different ways to estimate $\rho$ [Ganninger, 2009].
  The classical ANOVA estimator:
	\begin{align*}
		\hat{\rho} = \dfrac{ \widehat{SSB}(n_\RN{1}-1)^{-1} -  \widehat{SSW}(n-n_\RN{1})^{-1}}{ \widehat{SSB}+(K-1) \widehat{SSW}(n-n_\RN{1})^{-1} }\;{,}
	\end{align*}%
where $ \widehat{SSB} =  \sum_{i \in \mathfrc{s}_{\RN{1}}} n_i (\overline{y}_i - \overline{y})^2 $ and 

with  $ \widehat{SSW}  = \sum_{i \in \mathfrc{s}_{\RN{1}}} (n_i - 1) s^2_i$ and 
$$
 K = (N_\RN{1}-1)^{-1} \left( n - \sum_{ i \in \mathfrc{s}_\RN{1} }  \dfrac{n_\RN{1}^2}{n} \right) \;{.}
$$
}\onslide<2>{
\begin{itemize}
\item The model-based approach is widely used because it presents for data users often the only option to estimate a design effect.
\item For multi-stage design the used model considers only the cluster effect of the PSU's and neglects any subsequent sampling stages.
\end{itemize}
}
\end{frame}

\begin{frame}
	\frametitle{Effective Sample Size Use of $\deff$}
	\begin{description}
		\item[a priori] Prediction of a minimum net sample size (e.g. in the ESS):
					\[
					  \tilde{n}_{net} = \neff \times \deff_{pre} = \neff \times \left[ 1 + \left(\bar{b}_{pre} - 1 \right) \rho_{pre}  \right]
					\,{.}\]
		\item[a posteriori] Estimation of $\deff$ based on a realized complex sample.
	\end{description}	
\end{frame}



\begin{frame}{Average Design Effects in the ESS}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}

{\centering \includegraphics[width=.9\linewidth]{graphs/deff_cntryAll_roundALL} 

}
%\caption[Average Design Effects in the ESS]{Average Design Effects in the ESS}\label{fig:SamSizeSRSprobs2}
\end{figure}
\end{frame}

\begin{frame}[allowframebreaks]\frametitle{Literature}    
%\scriptsize
  \begin{thebibliography}{10}    
   \setbeamertemplate{bibliography item}[article]
  \bibitem{GablerEtal1999}
  S.~Gabler, S.~H\"{a}der, \& P.~Lahiri.
    \newblock  A Model Based Justification of
Kish's Formula for Design Effects for Weighting and Clustering.
    \newblock {\em Survey Methodology}, 1999.
  \setbeamertemplate{bibliography item}[book]
  \bibitem{Ganninger2009}
   M.~Ganninger.
  \newblock  Design Effects: Model-based versus Design-based Approach
  \newblock  PhD Thesis, {\em GESIS-Schriftenreihe Band 3}, 2009
    \bibitem{Saerndal1992}
    C.-E.~S\"{a}rndal, B.~Swensson, \& J.~Wretman.
    \newblock Model Assisted Survey Sampling
    \newblock {\em Springer}, 1992.
    \setbeamertemplate{bibliography item}[book]
  \bibitem{Tille2006}
   Y.~Till\'{e}.
  \newblock  Sampling Algorithms
    \newblock {\em Springer Series in Statistics: Springer}, 2006.
  \end{thebibliography}
\end{frame} 





\end{document}
