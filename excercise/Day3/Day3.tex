\documentclass[11pt,german,hideothersubsections]{beamer}

\usepackage{hyperref}
\usepackage{amsmath,nicefrac,booktabs,mathabx}
\usepackage{natbib}
\usepackage{url}
\usepackage{textpos}
\usepackage{listings}
\definecolor{Rblau}{rgb}{.3,.6,.9}

\lstset{language=R,
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\bfseries,
        identifierstyle=\color{Rblau},
        commentstyle=\color{gray},
        stringstyle=\color{green}\ttfamily,
        showstringspaces=false,
        frame=tb}



\bibpunct{(}{)}{;}{a}{,}{,}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{helvet}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow,dcolumn}
\usepackage{ragged2e}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{tikz}
\usetikzlibrary{calc}
\usepackage{booktabs}
\colorlet{tablesubheadcolor}{gray!25}
\colorlet{tableheadcolor}{gray!40}
\colorlet{tablerowcolor}{gray!15.0}
\usetheme[english]{Gesis}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]%{\hspace*{.2cm}\insertframenumber}
\setbeamerfont{caption}{size=\footnotesize}
\usefonttheme[onlylarge]{structuresmallcapsserif} % alte Schrift

\newcommand{\R}[1]{{\tt \color{blue}  #1}}
\newtheorem{thm}{Theorem}
\newtheorem{rem}{Bemerkung}
\newtheorem{lem}{Lemma}

\definecolor{hellgrau}{rgb}   {0.109375,  0.40625,   0.51953125}
\definecolor{dunkelgrau}{rgb} {0.009375,  0.30625,   0.41953125}
\definecolor{dunkelgrau2}{rgb}{0.009375,  0.20625,   0.31953125}
\definecolor{hellbraun}{rgb}  {0.9140625, 0.8984375, 0.8046875}
\definecolor{hellbraun2}{rgb} {.95,       0.9,       0.8}
\definecolor{alertred}{rgb}   {0.8515625, 0.3828125, 0.08984375}
\definecolor{orange}{rgb}{1,0.5,0}


\setbeamercolor{firstsecslide}{fg=white,bg=dunkelgrau}
\setbeamertemplate{blocks}[rounded][shadow=true]

\newcolumntype{d}[0]{D{,}{.}{6}}

\newenvironment{itemizeol}{\begin{itemize}[<+->]}{\end{itemize}}
\newenvironment{descriptionol}{\begin{description}[<+->]}{\end{description}}

\newcolumntype{V}[1]{%
  >{\RaggedRight\hspace{0pt}}p{#1}%
}

\newcommand{\emphred}[1]{\textcolor{alertred}{#1}}
\newcommand{\emphcol}[1]{\textcolor{dunkelgrau}{\slshape #1}}

\setcounter{tocdepth}{1}
\setbeamercolor*{section in toc}{fg=hellgrau}
\setbeamertemplate{bibliography item}[default]
\makeatother
\addtobeamertemplate{frametitle}{}{%
\begin{textblock*}{100mm}(.91\textwidth,-1cm)
\includegraphics[height=1cm,width=2cm]{H:/Sand_Summerschool/SamplingAndEsimation/graphs/logos/GESIS_Logo_kompakt_en.jpg}
\end{textblock*}}
\title[Day 1]{Tutorial: Sampling, Weighting and Estimation\\ \Large{Day 3} }
%\subtitle{Umgang am Beispiel von Telefonstichproben}

\author[M. Sand]{Stefan Zins, Matthias Sand\\ and Jan-Philipp Kolb\\ \vspace{.5cm} \footnotesize{GESIS - Leibniz Institute\\ for the Social Sciences}}
%\institute{\includegraphics[width=4.5cm]{GESIS_Logo_informell}}
\date[]{\color{dunkelgrau}\footnotesize%
\begin{minipage}{8cm}%
\begin{center}%
\scriptsize{
\textbf{GESIS Summer School}\\ \tiny{Cologne, Germany}%
}\\
\vspace{0.25cm}
\textbf{August 26th, 2015}%

\end{center}%
\end{minipage}}%


\usepackage{Sweave}
\begin{document}
\input{Day3-concordance}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Probability of Inclusion}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Probability of Inclusion}\end{center}}
\footnotesize{
\vspace{-.25cm}
\begin{center}
\textbf{First order inclusion probability under SRSWOR}
\end{center}
\begin{equation*}
\pi_k=\frac{n}{N}
\end{equation*}

\begin{Schunk}
\begin{Sinput}
 N <- nrow(bm)
 n <- 180
 pik <- rep(n/N,N)
\end{Sinput}
\end{Schunk}
\begin{center}
\pause\textbf{First order inclusion probability under StrRS}
\end{center}
\begin{equation*}
\pi_{hk}=\frac{n_h}{N_h} 
\end{equation*}

\begin{Schunk}
\begin{Sinput}
 Nh <- table(bm$Province)
 nh <- c(15,20,35,22,18,22,7,13,20)
 pihk <- data.frame(nh/Nh)
 names(pihk)[1] <- "Province"
 pihk.long <- merge(pihk,bm,by = "Province")
\end{Sinput}
\end{Schunk}
\begin{itemize}
\pause\item Or with the \R{sampling} package
\end{itemize}
\begin{Schunk}
\begin{Sinput}
 pihk.sa <- inclusionprobastrata(bm$Province,nh)
\end{Sinput}
\end{Schunk}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Probability of Inclusion}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Probability of Inclusion}\end{center}}
\footnotesize{
\begin{center}
\textbf{First order inclusion probability under $\pi$ps}
\end{center}
\begin{equation*}
\pi_k=\frac{x_k}{\sum_{l=1}^{N}x_l}*n
\end{equation*}

\begin{Schunk}
\begin{Sinput}
 phi <- bm$Tot04/sum(bm$Tot04)
 pik <- phi*n
 head(pik)
\end{Sinput}
\begin{Soutput}
[1] 0.2443 7.9021 0.2066 0.2714 0.1776 0.6403
\end{Soutput}
\end{Schunk}
\begin{itemize}\footnotesize{
\pause\item[$\Rightarrow$] Sampling frequencies $>1$
\item[$\Rightarrow$] With replacement $\rightarrow$ average frequency of element $k$ in sample
\item[$\Rightarrow$] Without replacement $\rightarrow$ each element can only be chosen once}
\end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Probability of Inclusion}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Probability of Inclusion}\end{center}}
\footnotesize{
\begin{center}
\textbf{$\pi$ps and the \R{sampling} package}
\end{center}
\begin{Schunk}
\begin{Sinput}
 pik <- inclusionprobabilities(bm$Tot04,n)
 head(pik)
\end{Sinput}
\begin{Soutput}
[1] 0.2885 1.0000 0.2439 0.3205 0.2097 0.7561
\end{Soutput}
\begin{Sinput}
 table(pik == 1)
\end{Sinput}
\begin{Soutput}
FALSE  TRUE 
  562    27 
\end{Soutput}
\end{Schunk}
\begin{itemize}
\pause\item[$\Rightarrow$] The command \R{inclusionprobabilites} displays the first order inclusion probability $\rightarrow$ not the average sampling frequencies
\item[$\Rightarrow$] It sets every frequency $>1$ to $1$ and redistributes the "rest", because:
\pause\item[$\Rightarrow$] $0<\pi_k\leq 1$
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{The Horvitz-Thompson-Estimator}
\end{center}
\begin{equation*}
\hat{t}_{HT}=\sum_{k=1}^{n} d_k*y_k=\sum_{k=1}^{n} \frac{1}{\pi_k}y_k
\end{equation*}

\begin{Schunk}
\begin{Sinput}
 s <- strata(bm,"Province",nh, "srswor")
 samp <- getdata(bm,s)
 dk <- 1/samp$Prob
 sum(dk*samp$Men04)
\end{Sinput}
\begin{Soutput}
[1] 5681894
\end{Soutput}
\end{Schunk}
\pause
\begin{Schunk}
\begin{Sinput}
 sum(bm$Men04)
\end{Sinput}
\begin{Soutput}
[1] 5097709
\end{Soutput}
\end{Schunk}
The \R{sampling} package also offers a function for the HT-estimator
\begin{Schunk}
\begin{Sinput}
 HTstrata(y = samp$Men04,pik = samp$Prob,strata = samp$Province)
\end{Sinput}
\begin{Soutput}
[1] 5681894
\end{Soutput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Scaling design weights to sample size}
\end{center}

\begin{itemize}
\item Typically the sum of design weights adds up to the population size ($\sum_{k=1}^{n}d_k=N$)
\item It is common to use scaled weights ($d_k^*$) that add up to the sample size and have a mean of $1$  ($\sum_{k=1}^{n}d_k^*=n$; $d_k^*=n*\frac{d_k}{\sum_{l=1}^n d_l}$)
\item[$\Rightarrow$] Advantage: you see if an element has a higher or lower probability to be included in your sample 
\end{itemize}
\vspace{.25cm}
\begin{Schunk}
\begin{Sinput}
 dk.sc <- nrow(samp)*dk/sum(dk)
 sum(dk.sc*samp$Men04)/nrow(samp)
\end{Sinput}
\begin{Soutput}
[1] 9647
\end{Soutput}
\end{Schunk}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Truncating weights}
\end{center}
\begin{itemize}
\item Truncating the weights within specific borders to avoid high and/ or negative weights
\item MSE argument: trade-off between biased results and lower variance
\item Algorithm should rescale the weights to its previous sum
\end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\tiny{
\begin{Schunk}
\begin{Sinput}
 trunc.bounds<-function(di,bound){
+   n<-sum(di)
+   nopt<-di
+   i<-0
+   s<-which(di<=0|di<bound[1]|di>bound[2])
+   while(i<n){
+       if(length(s)!=0){
+       s1<-which(nopt<=0)
+       s2<-which(nopt<bound[1])
+       s3<-which(nopt>bound[2])
+       nopt[s1]<-bound[1]
+       nopt[s2]<-bound[1]
+       nopt[s3]<-bound[2]
+       su<-length(s1)*bound[1]+length(s2)*bound[1]+length(s3)*bound[2]
+       ge<-(n-su)*nopt[-s]/sum(nopt[-s])
+       nopt[-s]<-ge
+       s<-which(nopt<=0|nopt<bound[1]|nopt>bound[2])}
+       if(length(s)!=0){
+       i<- i+1
+       fi<-i}
+       else {
+         fi<-i+1
+         i<-n
+       }
+     }
+   cat(" number of iterations ",fi,"\n",
+       "number of truncated weights ",length(which(nopt%in%bound)),"\n",
+   "minimal value",sum(di^2/nopt))
+   return(nopt)
+ }
\end{Sinput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Truncating weights (example) }
\end{center}

\begin{Schunk}
\begin{Sinput}
 wei <- runif(5000,0.5,7)
 table(wei>=6)
\end{Sinput}
\begin{Soutput}
FALSE  TRUE 
 4223   777 
\end{Soutput}
\begin{Sinput}
 bounds <- c(0,6)
 wei.trunc <- trunc.bounds(wei,bounds)
\end{Sinput}
\begin{Soutput}
 number of iterations  18 
 number of truncated weights  925 
 minimal value 18908
\end{Soutput}
\begin{Sinput}
 table(wei.trunc==6)
\end{Sinput}
\begin{Soutput}
FALSE  TRUE 
 4075   925 
\end{Soutput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Variance of the HT-Estimator}
\end{center}
\begin{equation*}
V_{SYG}(\hat{t}_{HT})=\sum_{\substack{k=1\\ k<l}}^N\sum_{l=1}^N (\pi_k*\pi_l-\pi_{kl})*(\frac{y_k}{\pi_k}-\frac{y_l}{\pi_l})^2
\end{equation*}

\begin{Schunk}
\begin{Sinput}
 bm <- bm[-2,]
 pik <- inclusionprobabilities(bm$Tot03,30)
 IPkl1 <- UPsampfordpi2(pik)
 IPkl2 <- UPsystematicpi2(pik)
 SIGMA.samp <- IPkl1 - pik%*%t(pik)
 SIGMA.syst <- IPkl2 - pik%*%t(pik)
\end{Sinput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Variance of the HT-Estimator}
\end{center}

\begin{Schunk}
\begin{Sinput}
 var.HT.tot.samp <- t(bm$Tot04/pik
+                     )%*%SIGMA.samp%*%(bm$Tot04/pik)
 var.HT.tot.sys<- t(bm$Tot04/pik
+                     )%*%SIGMA.syst%*%(bm$Tot04/pik)
 var.HT.tot.samp
\end{Sinput}
\begin{Soutput}
         [,1]
[1,] 92926611
\end{Soutput}
\begin{Sinput}
 var.HT.tot.sys
\end{Sinput}
\begin{Soutput}
          [,1]
[1,] 113132108
\end{Soutput}
\end{Schunk}
\begin{itemize}
\pause\item Same design weights
\item Different sampling algorithm
\item[$\Rightarrow$] Different Variance!
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{The HT-Estimator: Variance Estimation}
\end{center}
\begin{equation*}
\hat{V}_{SYG}(\hat{t}_{HT})=\sum_{\substack{k=1\\ k<l}}^n\sum_{l=1}^n \frac{\pi_k*\pi_l-\pi_{kl}}{\pi_{kl}}*(\frac{y_k}{\pi_k}-\frac{y_l}{\pi_l})^2
\end{equation*}

\begin{Schunk}
\begin{Sinput}
 s <- UPsystematic(pik)
 samp <- getdata(bm,s)
 SIGMA.s <- SIGMA.syst[s==1,s==1]
 SIGMA.s.tilde <- SIGMA.s/IPkl2[s==1,s==1]
 var.hat.HT.tot.syst <- t(samp$Tot04/pik[s==1]
+                     )%*%SIGMA.s.tilde%*%(samp$Tot04/pik[s==1])
 var.hat.HT.tot.syst
\end{Sinput}
\begin{Soutput}
          [,1]
[1,] 7.403e+13
\end{Soutput}
\end{Schunk}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Effects}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Effects}\end{center}}
\footnotesize{
\begin{center}
\textbf{Design-based approach}
\end{center}
\begin{equation*}
deff=\frac{Var_c(\hat{t})}{Var_{srs}(\hat{t})}
\end{equation*}

\begin{Schunk}
\begin{Sinput}
 var.tot.srs <- var(bm$Tot04)/30*(1-30/nrow(bm))*nrow(bm)^2
 deff <- var.HT.tot.samp/var.tot.srs
 deff
\end{Sinput}
\begin{Soutput}
          [,1]
[1,] 1.881e-05
\end{Soutput}
\end{Schunk}
\begin{itemize}
\item Although the sample has been drawn with unequal probabilities, the design effect is below 1
\item[$\Rightarrow$] Highly correlated variable has been used to calculate the inclusion probabilities 
\end{itemize}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Effects}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Effects}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Model-based approach}
\end{center}
\begin{equation*}
\hat{deff}=\hat{deff_p} * \hat{deff_c} = n\frac{\sum_{h=1}^ld_h^2 n_h}{(\sum_{h=1}^ld_h n_h)^2}*(1+(\overline{b}-1)\rho)
\end{equation*}

\begin{itemize}
\item[] \alert{$n_h$} is the number of units per cluster; \alert{$\overline{b}$} is the average cluster size; \alert{$\rho$} reflects the Intraclass Correlation Coefficient (ICC)
\pause\item[$\Rightarrow$] No cluster/ stratified random sample
\item[$\Rightarrow$] $deff_p$ captures the design effect due to unequal inclusion probabilities
\end{itemize}

\begin{Schunk}
\begin{Sinput}
 deff_p <- sum(30*(1/pik[s==1])^2)/sum(1/pik[s==1])^2
 deff_p
\end{Sinput}
\begin{Soutput}
[1] 2.258
\end{Soutput}
\end{Schunk}
\pause\begin{center}
\textbf{Effective sample size}
\end{center}
\begin{equation*}
n_{eff}=\frac{n}{deff}
\end{equation*}
 
\begin{Schunk}
\begin{Sinput}
 30/deff
\end{Sinput}
\begin{Soutput}
        [,1]
[1,] 1594905
\end{Soutput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Calibration}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Calibration}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Poststratification}
\end{center}

Using the my.pop data set of day 1
\begin{Schunk}
\begin{Sinput}
 s <- srswor(100,10000)
 samp <- my.pop[s==1,]
 genXedu.s <- data.frame(table(samp$gender,samp$education))
 genXedu.s[,3] <- genXedu.s[,3]/sum(genXedu.s[,3])
 genXedu.pop <- data.frame(table(my.pop$gender,my.pop$education))
 genXedu.pop[,3] <- genXedu.pop[,3]/sum(genXedu.pop[,3])
 adj.w <- data.frame(genXedu.pop[,3]/genXedu.s[,3])
 adj.w[,1]
\end{Sinput}
\begin{Soutput}
[1] 0.7626 1.2745 0.8618 0.7132 2.0489 0.8720 1.8350 1.2467
\end{Soutput}
\begin{Sinput}
 samp$to.merge <- paste(samp$gender,samp$education)
 adj.w$to.merge <- paste(genXedu.s$Var1,genXedu.s$Var2)
 adjusted <- merge(adj.w,samp,by="to.merge")
\end{Sinput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Calibration}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Calibration}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Raking/ Iterative Proportional Fitting}
\end{center}
Generating the necessary data frames
\begin{Schunk}
\begin{Sinput}
 age <- rep(as.character(1:6),times=10)
 edu <- rep(as.character(1:5),each=6,times=2)
 gender <- rep(c("m","w"),each=30)
 freq <- sample(100,60,replace=T)
 # Synthetic sample distribution
 samp <- data.frame(age,edu,gender,freq)
 samp[,4] <- samp[,4]/sum(samp[,4])
 freq2 <- sample(100,60,replace=T)
 # in population
 master <- data.frame(age,edu,gender,freq2)
 master[,4] <- master[,4]/sum(master[,4])
 masageXedu <- aggregate(master[,4],
+                         list(age=master[,1],edu=master[,2]),sum)
 masageXgen <- aggregate(master[,4],
+                         list(age=master[,1],gender=master[,3]),sum)
 maseduXgen <- aggregate(master[,4],
+                         list(edu=master[,2],gender=master[,3]),sum)
\end{Sinput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Calibration}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Calibration}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Raking/ Iterative Proportional Fitting}
\end{center}
\tiny{
\begin{Schunk}
\begin{Sinput}
 w_0 <- rep(1,times=nrow(samp))
 times <- 0
 while(times <= 1000){
+   #AgexEducation
+   saxe <- aggregate(samp[,4]*w_0,list(age=samp[,1],edu=samp[,2]),sum)
+   w_1 <- masageXedu[,3]/saxe[,3]
+   w_1 <- rep(w_1,times=(nrow(samp)/nrow(saxe)))
+   #AgexGender
+   saxg <- aggregate(samp[,4]*w_0*w_1,list(age=samp[,1],gen=samp[,3]),sum)
+   w_2 <- masageXgen[,3]/saxg[,3]
+   w_2 <- c(rep(w_2[1:(length(w_2)/2)],times=(nrow(samp)/nrow(saxg))),
+          rep(w_2[(length(w_2)/2+1):length(w_2)],times=(nrow(samp)/nrow(saxg))))
+   #EducationxGender
+   sexg <- aggregate(samp[,4]*w_0*w_1*w_2,list(edu=samp[,2],gen=samp[,3]),sum)
+   w_3 <- maseduXgen[,3]/sexg[,3]
+   w_3 <- rep(w_3,each=(nrow(samp)/nrow(sexg)))
+   #w4
+   w_4 <- w_0*w_1*w_2*w_3
+   if(max(abs(w_0-w_4))>0.05)
+           {w_0<-w_4
+           times<-times+1}
+   else {break}
+   cat("iteration",times,"\n")
+ }
\end{Sinput}
\begin{Soutput}
iteration 1 
iteration 2 
iteration 3 
iteration 4 
iteration 5 
\end{Soutput}
\begin{Sinput}
 samp$weight<-w_0*samp[,4]
\end{Sinput}
\end{Schunk}
}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Calibration}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Calibration}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Raking/ Iterative Proportional Fitting}
\end{center}
\begin{Schunk}
\begin{Sinput}
 sampeduXgen<-aggregate(samp[,5],list(edu=samp[,2],gen=samp[,3]),sum)
\end{Sinput}
\end{Schunk}
\begin{columns}
\begin{column}{.5\textwidth}
\begin{Schunk}
\begin{Sinput}
 sampeduXgen
\end{Sinput}
\begin{Soutput}
   edu gen       x
1    1   m 0.09474
2    2   m 0.09211
3    3   m 0.09836
4    4   m 0.09309
5    5   m 0.10395
6    1   w 0.10000
7    2   w 0.10724
8    3   w 0.12204
9    4   w 0.10395
10   5   w 0.08454
\end{Soutput}
\end{Schunk}
\end{column}
\begin{column}{.5\textwidth}
\begin{Schunk}
\begin{Sinput}
 maseduXgen
\end{Sinput}
\begin{Soutput}
   edu gender       x
1    1      m 0.09474
2    2      m 0.09211
3    3      m 0.09836
4    4      m 0.09309
5    5      m 0.10395
6    1      w 0.10000
7    2      w 0.10724
8    3      w 0.12204
9    4      w 0.10395
10   5      w 0.08454
\end{Soutput}
\end{Schunk}
\end{column}
\end{columns}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%{The survey package}%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{itemize}
\item The survey package provides a large range of applications for complex survey samples
\item Typically, the first step is to define a survey object with the \R{svydesign()} command
\end{itemize}
\begin{center}
\textbf{Simple survey object (single stage)}
\end{center}
\begin{Schunk}
\begin{Sinput}
 library(Matrix)
 library(survey)
 bm$pik1 <- inclusionprobabilities(bm$Tot03,100)
 s <- UPmaxentropy(bm$pik1)
 samp <- getdata(bm,s)
 IPkl <- UPmaxentropypi2(bm$pik1)
 surv.obj <- svydesign(id=~1,fpc = samp$pik1,
+                data = samp,pps = ppsmat(IPkl[s==1,s==1]),
+                variance = "YG")
\end{Sinput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{Schunk}
\begin{Sinput}
 surv.obj <- svydesign(id=~1,fpc = samp$pik1,
+               data = samp,pps = ppsmat(IPkl[s==1,s==1]),
+               variance = "YG")
\end{Sinput}
\end{Schunk}
}
\begin{itemize}
\item \R{id} specifies the identifier of PSU and SSU;\R{id$=$ \textasciitilde0} or \R{id$=$\textasciitilde1} stipulates a single stage sampling
\item For multi-stage samples the \R{id} argument should always specify a formula with the cluster-identifier at each stage
\item \R{fpc} should be used for the finite population correction
\item[$\Rightarrow$] Either as the total population size of each stratum or as a fraction of the total population that has been sampled 
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{Schunk}
\begin{Sinput}
 surv.obj <- svydesign(id=~1,fpc = samp$pik,
+                 data = samp,pps = ppsmat(IPkl[s==1,s==1]),
+                 variance = "YG")
\end{Sinput}
\end{Schunk}
}
\begin{itemize}
\item \R{data} reflects the data set for which the design object should be defined
\item \R{pps} should be used to define the design information that should be used; usually the second order probability of inclusion
\item[$\Rightarrow$] \R{ppsmat()} is a wrapper for the joint inclusion probabilities of the HT-Estimator
\item With \R{variance} you can specify whether you use the Yates-Grundy- or the HT-Estimator
\item[$\Rightarrow$] For fixed sample sizes, "YG" should be used
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Important commands}
\end{center}
\begin{tabular}{ll}
\R{svytotal} & returns the estimated total of a variable \\ & and its standard error ($+ deff$)\\
\R{svymean} & returns the estimated mean of a variable\\ & and its standard error ($+ deff$)\\
\R{svyquantile} & Computes quantiles for data from complex surveys\\
\R{svyvar} & Computes variances  for data from complex surveys\\
\R{weights} & Returns the (design) weights of a survey object\\
\R{calibrate} & Calibration of a data set (uses the GREG-Estimator)\\
... & ...\\
\end{tabular}

\begin{Schunk}
\begin{Sinput}
 svytotal(~Tot04,surv.obj)
\end{Sinput}
\begin{Soutput}
        total   SE
Tot04 9957554 3770
\end{Soutput}
\end{Schunk}
}
\end{frame}
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Example: changing the "YG" argument with fixed sample sizes}
\end{center}

\begin{Schunk}
\begin{Sinput}
 surv.obj2 <- svydesign(id=~1,fpc = samp$pik,
+              data = samp,pps = ppsmat(IPkl[s==1,s==1])
+              ,variance = "HT")
 svytotal(~Tot04,surv.obj2)
\end{Sinput}
\begin{Soutput}
        total SE
Tot04 9957554 NA
\end{Soutput}
\end{Schunk}
\begin{itemize}
\pause\item[$\Rightarrow$] The variance estimator under HT varies more than the ont of the YG estimator
\pause\item[$\Rightarrow$] In this case the estimator is negative
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Calibrating the sample}
\end{center}
\footnotesize{
The GREG-Estimator within the survey package}
\begin{Schunk}
\begin{Sinput}
 svymean(~averageincome,surv.obj)
\end{Sinput}
\begin{Soutput}
               mean  SE
averageincome 25515 455
\end{Soutput}
\begin{Sinput}
 mean(bm$averageincome)
\end{Sinput}
\begin{Soutput}
[1] 25095
\end{Soutput}
\end{Schunk}
\begin{itemize}\footnotesize{
\item Using the variable Men03 and Arrondiss as auxiliary information 
\item Calculating the population Total}
\end{itemize}

\begin{Schunk}
\begin{Sinput}
 lm1 <- lm(averageincome ~Men03+Arrondiss, data=bm)
 pop.tot <- colSums(model.matrix(lm1))
\end{Sinput}
\end{Schunk}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Calibrating the sample}
\end{center}

\begin{itemize}\footnotesize{
\item Calculation the calibration weights with the \R{calibrate()} command}
\end{itemize}

\begin{Schunk}
\begin{Sinput}
 surv.obj3 <- svydesign(id=~0,fpc = samp$pik1,
+                        data = samp,pps = "brewer")
\end{Sinput}
\end{Schunk}
\begin{itemize}
\item The \R{calibrate} function cannot be applied to the previous object of class "ppsmat"
\item[$\Rightarrow$] Therefore we use the brewer approximation for joint inclusion probabilities
\pause\item[$\Rightarrow$] Seems odd, since only first order inclusion probabilities are used for calibration
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Calibrating the sample}
\end{center}

\begin{Schunk}
\begin{Sinput}
 g_i <- calibrate(surv.obj3,formula =~Men03+Arrondiss
+                  ,population=pop.tot,calfun="linear")
\end{Sinput}
\end{Schunk}
\begin{itemize}
\item The names of the variables that are used for the calibration have to be identical for your survey object and your population
\item \R{formula} specifies the calibration model
\item With \R{calfun} you can choose between a linear model (GREG) or a raking approach
\item For only one calibration variable, \R{calibrate} produces the same weights as a poststratification
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\vspace{-.25cm}
\begin{center}
\textbf{Calibration results}
\end{center}
\footnotesize{
\vspace{.25cm}
\begin{columns}
\begin{column}{.5\textwidth}
\begin{block}{Sample}
\begin{Schunk}
\begin{Sinput}
 svymean(~averageincome,g_i)
\end{Sinput}
\begin{Soutput}
               mean  SE
averageincome 25185 391
\end{Soutput}
\begin{Sinput}
 svytotal(~Men03,g_i)
\end{Sinput}
\begin{Soutput}
        total SE
Men03 4853501  0
\end{Soutput}
\begin{Sinput}
 svytotal(~Arrondiss,g_i)
\end{Sinput}
\begin{Soutput}
          total SE
Arrondiss 27744  0
\end{Soutput}
\end{Schunk}
\end{block}
\end{column}
\begin{column}{.5\textwidth}
\vspace{-1cm}
\begin{block}{Population}
\begin{Schunk}
\begin{Sinput}
 mean(bm$averageincome)
\end{Sinput}
\begin{Soutput}
[1] 25095
\end{Soutput}
\begin{Sinput}
 sum(bm$Men03)
\end{Sinput}
\begin{Soutput}
[1] 4853501
\end{Soutput}
\begin{Sinput}
 sum(bm$Arrondiss)
\end{Sinput}
\begin{Soutput}
[1] 27744
\end{Soutput}
\end{Schunk}
\end{block}
\end{column}
\end{columns}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\vspace{-.25cm}
\begin{center}
\textbf{Multi-stage samples}
\end{center}
\footnotesize{
Loading the \R{api} data set and generating a \emph{multi-stage} data frame

\begin{Schunk}
\begin{Sinput}
 data(api)
 score <- by(apiclus1,apiclus1$cds,
+         function(x)rnorm(x$api.stu,mean = x$api00, sd = sqrt(x$api00)))
\end{Sinput}
\end{Schunk}

\begin{itemize}
\item the \R{by} command is similar to \R{tapply} and creates a list of normal distributed test scores for each school 
\end{itemize}

\begin{Schunk}
\begin{Sinput}
 l <- 50
 nh <- 60
 apiclus1$fpc <- inclusionprobabilities(apiclus1$enroll,l)
\end{Sinput}
\end{Schunk}

\begin{itemize}
\item We draw a sample of $l=50$ schools (PSUs) proportional to the number of enrolled pupils
\end{itemize}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Sampling the cluster}
\end{center}

\begin{Schunk}
\begin{Sinput}
 cs <- UPmaxentropy(apiclus1$fpc)
 cs.dat <- apiclus1[cs==1,]
\end{Sinput}
\end{Schunk}

\vspace{.5cm}
\begin{center}
\textbf{Sampling within a school}
\end{center}

\begin{Schunk}
\begin{Sinput}
 score.cs.dat <- score[as.character(cs.dat$cds)]
 score.samp <- lapply(score.cs.dat,function(x)x[sample(length(x),nh)])
 names(score.samp) <- names(score.cs.dat)
 data.s <- data.frame(score = unlist(score.samp),
+           cds=rep(names(score.samp),
+                   times=sapply(score.samp,length)))
\end{Sinput}
\end{Schunk}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Merging the data sets/ Second stage inclusion probabilities}
\end{center}

\begin{Schunk}
\begin{Sinput}
 DATA.s <- merge(cs.dat,data.s,by="cds")
 DATA.s$id <- 1:nrow(DATA.s)
 DATA.s$fpc2 <- nh/DATA.s$enroll
\end{Sinput}
\end{Schunk}

\begin{itemize}
\item[$\Rightarrow$] Full sample of 50 PSUs with 60 SSUs each
\item[$\Rightarrow$] \emph{Self-weighting} approach
\end{itemize}

\pause\begin{center}
\textbf{Specifying the survey object}
\end{center}

\begin{Schunk}
\begin{Sinput}
 mul.surv <- svydesign(id=~cds+id,fpc = ~fpc+fpc2,
+                       data=DATA.s, pps="brewer")
 svymean(~api00,mul.surv)
\end{Sinput}
\begin{Soutput}
      mean   SE
api00  625 12.4
\end{Soutput}
\begin{Sinput}
 table(weights(mul.surv))
\end{Sinput}
\begin{Soutput}
33.3914893617021             35.1 35.7833333333333            36.35 
            2820               60               60               60 
\end{Soutput}
\end{Schunk}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Exercise 4}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Exercise 4}\end{center}}
\footnotesize{
\begin{exampleblock}{Design effects/ One-stage cluster sample}
\begin{enumerate}\footnotesize{
\item Draw a sample of $l=20$ FULL arondissments proportional to the population of 2003
\begin{itemize}
\item[$\Rightarrow$] Use the maximum entropy algorithm
\end{itemize}
\item Calculate the design effect by the model based approach
\begin{block}{Model based approach}
\begin{equation*}
\hat{deff}=\hat{deff_p} * \hat{deff_c} = n\frac{\sum_{h=1}^ld_h^2 n_h}{(\sum_{h=1}^ld_h n_h)^2}*(1+(\overline{b}-1)\rho)
\end{equation*}
\begin{equation*}
\hat{\rho}^{AOV}=\frac{MSB-MSW}{MSB+(K-1)MSW}
\end{equation*}
\begin{equation*}
MSB=\frac{SSB}{l-1}\text{;~~~~~~~}MSW=\frac{SSW}{n-l}\text{;~~~~~~~}K=\frac{1}{l-1}(n-\sum_{h=1}^l\frac{n_h^2}{n})
\end{equation*}
\end{block}
}
\end{enumerate}
\end{exampleblock}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Exercise 4}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Exercise 4}\end{center}}
\footnotesize{
\begin{exampleblock}{Design effects/ One-stage cluster sample}
\begin{enumerate}\footnotesize{
\begin{block}{R-code MSW/ MSB}
\begin{Schunk}
\begin{Sinput}
 ### MSW and MSB 
 SS <- anova(lm(DATA.c$Tot04~DATA.c$Arrondiss))
 MSB <- SS$`Mean Sq`[1]
 MSW <- SS$`Mean Sq`[2]
\end{Sinput}
\end{Schunk}
\end{block}
\item[3] Calculate deff under the design based approach
\item[4] Calculate the effective sample size}
\end{enumerate}
\end{exampleblock}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Exercise 5}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Exercise 5}\end{center}}
\footnotesize{
\begin{exampleblock}{The survey package/ Multi-stage sampling}
\begin{enumerate}
\item Create the normal distributed income for each individual in 2004 within each commune of the belgianmunicipalities data set (use the square root of the average income as the standard deviation)
\item Draw a sample of $l=50$ communes (use the INS as identifier) proportional to the population of 2003
\item Draw a sample of $n_h=80$ individuals within each commune
\item Estimate the mean income of your sample (design weighted)
\item Poststratify your data set to the number of men in 2003
\end{enumerate}
\end{exampleblock}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{frame}[fragile]{Exercise 6}
% %\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Exercise 4}\end{center}}
% \footnotesize{
% \begin{exampleblock}{Multi-stage sampling}
% \begin{enumerate}\footnotesize{
% \item Draw 3 out of the 9 provinces using the maximum entropy algorithm. Use the variable \alert{Tot03} to calculate the probanility of inclusion of the PSUs
% \item Draw 5 arrondissments within each of the sampled PSUs proportional to their population of 2003.
% \item Estimate mean and variance using the survey package (use the "Brewer" approximation for the second order inclusion probabilities)
% }
% \end{enumerate}
% \end{exampleblock}
% }
% \end{frame}











\end{document}
