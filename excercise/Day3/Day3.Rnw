\documentclass[11pt,german,hideothersubsections]{beamer}

\usepackage{hyperref}
\usepackage{amsmath,nicefrac,booktabs,mathabx}
\usepackage{natbib}
\usepackage{url}
\usepackage{textpos}
\usepackage{listings}
\definecolor{Rblau}{rgb}{.3,.6,.9}

\lstset{language=R,
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\bfseries,
        identifierstyle=\color{Rblau},
        commentstyle=\color{gray},
        stringstyle=\color{green}\ttfamily,
        showstringspaces=false,
        frame=tb}



\bibpunct{(}{)}{;}{a}{,}{,}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{helvet}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow,dcolumn}
\usepackage{ragged2e}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{tikz}
\usetikzlibrary{calc}
\usepackage{booktabs}
\colorlet{tablesubheadcolor}{gray!25}
\colorlet{tableheadcolor}{gray!40}
\colorlet{tablerowcolor}{gray!15.0}
\usetheme[english]{Gesis}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]%{\hspace*{.2cm}\insertframenumber}
\setbeamerfont{caption}{size=\footnotesize}
\usefonttheme[onlylarge]{structuresmallcapsserif} % alte Schrift

\newcommand{\R}[1]{{\tt \color{blue}  #1}}
\newtheorem{thm}{Theorem}
\newtheorem{rem}{Bemerkung}
\newtheorem{lem}{Lemma}

\definecolor{hellgrau}{rgb}   {0.109375,  0.40625,   0.51953125}
\definecolor{dunkelgrau}{rgb} {0.009375,  0.30625,   0.41953125}
\definecolor{dunkelgrau2}{rgb}{0.009375,  0.20625,   0.31953125}
\definecolor{hellbraun}{rgb}  {0.9140625, 0.8984375, 0.8046875}
\definecolor{hellbraun2}{rgb} {.95,       0.9,       0.8}
\definecolor{alertred}{rgb}   {0.8515625, 0.3828125, 0.08984375}
\definecolor{orange}{rgb}{1,0.5,0}


\setbeamercolor{firstsecslide}{fg=white,bg=dunkelgrau}
\setbeamertemplate{blocks}[rounded][shadow=true]

\newcolumntype{d}[0]{D{,}{.}{6}}

\newenvironment{itemizeol}{\begin{itemize}[<+->]}{\end{itemize}}
\newenvironment{descriptionol}{\begin{description}[<+->]}{\end{description}}

\newcolumntype{V}[1]{%
  >{\RaggedRight\hspace{0pt}}p{#1}%
}

\newcommand{\emphred}[1]{\textcolor{alertred}{#1}}
\newcommand{\emphcol}[1]{\textcolor{dunkelgrau}{\slshape #1}}

\setcounter{tocdepth}{1}
\setbeamercolor*{section in toc}{fg=hellgrau}
\setbeamertemplate{bibliography item}[default]
\makeatother
\addtobeamertemplate{frametitle}{}{%
\begin{textblock*}{100mm}(.91\textwidth,-1cm)
\includegraphics[height=1cm,width=2cm]{../../graphs/logos/GESIS_Logo_kompakt_en.jpg}
\end{textblock*}}
\title[Day 1]{Tutorial: Sampling, Weighting and Estimation\\ \Large{Day 3} }
%\subtitle{Umgang am Beispiel von Telefonstichproben}

\author[M. Sand]{Stefan Zins, Matthias Sand\\ and Jan-Philipp Kolb\\ \vspace{.5cm} \footnotesize{GESIS - Leibniz Institute\\ for the Social Sciences}}
%\institute{\includegraphics[width=4.5cm]{GESIS_Logo_informell}}
\date[]{\color{dunkelgrau}\footnotesize%
\begin{minipage}{8cm}%
\begin{center}%
\scriptsize{
\textbf{GESIS Summer School}\\ \tiny{Cologne, Germany}%
}\\
\vspace{0.25cm}
\textbf{August 26th, 2015}%

\end{center}%
\end{minipage}}%


\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle
<<t,echo=F,eval=T>>=
options(prompt = " ")
options(digits=4)
library(knitr)
library(sampling)
data("belgianmunicipalities")
bm<-belgianmunicipalities
CA<-T
Ex<-T
set.seed(42)
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Probability of Inclusion}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Probability of Inclusion}\end{center}}
\footnotesize{
\vspace{-.25cm}
\begin{center}
\textbf{First order inclusion probability under SRSWOR}
\end{center}
\begin{equation*}
\pi_k=\frac{n}{N}
\end{equation*}

<<cache=CA>>=
N <- nrow(bm)
n <- 180
pik <- rep(n/N,N)
@
\begin{center}
\pause\textbf{First order inclusion probability under StrRS}
\end{center}
\begin{equation*}
\pi_{hk}=\frac{n_h}{N_h} 
\end{equation*}

<<cache=T>>=
Nh <- table(bm$Province)
nh <- c(15,20,35,22,18,22,7,13,20)
pihk <- data.frame(nh/Nh)
names(pihk)[1] <- "Province"
pihk.long <- merge(pihk,bm,by = "Province")
@
\begin{itemize}
\pause\item Or with the \R{sampling} package
\end{itemize}
<<>>=
pihk.sa <- inclusionprobastrata(bm$Province,nh)
@

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Probability of Inclusion}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Probability of Inclusion}\end{center}}
\footnotesize{
\begin{center}
\textbf{First order inclusion probability under $\pi$ps}
\end{center}
\begin{equation*}
\pi_k=\frac{x_k}{\sum_{l=1}^{N}x_l}*n
\end{equation*}

<<cache=CA>>=
phi <- bm$Tot04/sum(bm$Tot04)
pik <- phi*n
head(pik)
@
\begin{itemize}\footnotesize{
\pause\item[$\Rightarrow$] Sampling frequencies $>1$
\item[$\Rightarrow$] With replacement $\rightarrow$ average frequency of element $k$ in sample
\item[$\Rightarrow$] Without replacement $\rightarrow$ each element can only be chosen once}
\end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Probability of Inclusion}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Probability of Inclusion}\end{center}}
\footnotesize{
\begin{center}
\textbf{$\pi$ps and the \R{sampling} package}
\end{center}
<<>>=
pik <- inclusionprobabilities(bm$Tot04,n)
head(pik)
table(pik == 1)
@
\begin{itemize}
\pause\item[$\Rightarrow$] The command \R{inclusionprobabilites} displays the first order inclusion probability $\rightarrow$ not the average sampling frequencies
\item[$\Rightarrow$] It sets every frequency $>1$ to $1$ and redistributes the "rest", because:
\pause\item[$\Rightarrow$] $0<\pi_k\leq 1$
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{The Horvitz-Thompson-Estimator}
\end{center}
\begin{equation*}
\hat{t}_{HT}=\sum_{k=1}^{n} d_k*y_k=\sum_{k=1}^{n} \frac{1}{\pi_k}y_k
\end{equation*}

<<>>=
s <- strata(bm,"Province",nh, "srswor")
samp <- getdata(bm,s)
dk <- 1/samp$Prob
sum(dk*samp$Men04)
@
\pause
<<>>=
sum(bm$Men04)
@
The \R{sampling} package also offers a function for the HT-estimator
<<>>=
HTstrata(y = samp$Men04,pik = samp$Prob,strata = samp$Province)
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Scaling design weights to sample size}
\end{center}

\begin{itemize}
\item Typically the sum of design weights adds up to the population size ($\sum_{k=1}^{n}d_k=N$)
\item It is common to use scaled weights ($d_k^*$) that add up to the sample size and have a mean of $1$  ($\sum_{k=1}^{n}d_k^*=n$; $d_k^*=n*\frac{d_k}{\sum_{l=1}^n d_l}$)
\item[$\Rightarrow$] Advantage: you see if an element has a higher or lower probability to be included in your sample 
\end{itemize}
\vspace{.25cm}
<<>>=
dk.sc <- nrow(samp)*dk/sum(dk)
sum(dk.sc*samp$Men04)/nrow(samp)
@
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Truncating weights}
\end{center}
\begin{itemize}
\item Truncating the weights within specific borders to avoid high and/ or negative weights
\item MSE argument: trade-off between biased results and lower variance
\item Algorithm should rescale the weights to its previous sum
\end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\tiny{
<<cache=T>>=
trunc.bounds<-function(di,bound){
  n<-sum(di)
  nopt<-di
  i<-0
  s<-which(di<=0|di<bound[1]|di>bound[2])
  while(i<n){
      if(length(s)!=0){
      s1<-which(nopt<=0)
      s2<-which(nopt<bound[1])
      s3<-which(nopt>bound[2])
      nopt[s1]<-bound[1]
      nopt[s2]<-bound[1]
      nopt[s3]<-bound[2]
      su<-length(s1)*bound[1]+length(s2)*bound[1]+length(s3)*bound[2]
      ge<-(n-su)*nopt[-s]/sum(nopt[-s])
      nopt[-s]<-ge
      s<-which(nopt<=0|nopt<bound[1]|nopt>bound[2])}
      if(length(s)!=0){
      i<- i+1
      fi<-i}
      else {
        fi<-i+1
        i<-n
      }
    }
  cat(" number of iterations ",fi,"\n",
      "number of truncated weights ",length(which(nopt%in%bound)),"\n",
  "minimal value",sum(di^2/nopt))
  return(nopt)
}
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Truncating weights (example) }
\end{center}

<<>>=
wei <- runif(5000,0.5,7)
table(wei>=6)
bounds <- c(0,6)
wei.trunc <- trunc.bounds(wei,bounds)
table(wei.trunc==6)
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Variance of the HT-Estimator}
\end{center}
\begin{equation*}
V_{SYG}(\hat{t}_{HT})=\sum_{\substack{k=1\\ k<l}}^N\sum_{l=1}^N (\pi_k*\pi_l-\pi_{kl})*(\frac{y_k}{\pi_k}-\frac{y_l}{\pi_l})^2
\end{equation*}

<<cache=T>>=
bm <- bm[-2,]
pik <- inclusionprobabilities(bm$Tot03,30)
IPkl1 <- UPsampfordpi2(pik)
IPkl2 <- UPsystematicpi2(pik)
SIGMA.samp <- IPkl1 - pik%*%t(pik)
SIGMA.syst <- IPkl2 - pik%*%t(pik)
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{Variance of the HT-Estimator}
\end{center}

<<cache=T>>=
var.HT.tot.samp <- t(bm$Tot04/pik
                    )%*%SIGMA.samp%*%(bm$Tot04/pik)
var.HT.tot.sys<- t(bm$Tot04/pik
                    )%*%SIGMA.syst%*%(bm$Tot04/pik)
var.HT.tot.samp
var.HT.tot.sys
@
\begin{itemize}
\pause\item Same design weights
\item Different sampling algorithm
\item[$\Rightarrow$] Different Variance!
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Weighting}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Weighting}\end{center}}
\footnotesize{
\begin{center}
\textbf{The HT-Estimator: Variance Estimation}
\end{center}
\begin{equation*}
\hat{V}_{SYG}(\hat{t}_{HT})=\sum_{\substack{k=1\\ k<l}}^n\sum_{l=1}^n \frac{\pi_k*\pi_l-\pi_{kl}}{\pi_{kl}}*(\frac{y_k}{\pi_k}-\frac{y_l}{\pi_l})^2
\end{equation*}

<<cache=T>>=
s <- UPsystematic(pik)
samp <- getdata(bm,s)
SIGMA.s <- SIGMA.syst[s==1,s==1]
SIGMA.s.tilde <- SIGMA.s/IPkl2[s==1,s==1]
var.hat.HT.tot.syst <- t(samp$Tot04/pik[s==1]
                    )%*%SIGMA.s.tilde%*%(samp$Tot04/pik[s==1])
var.hat.HT.tot.syst
@
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Effects}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Effects}\end{center}}
\footnotesize{
\begin{center}
\textbf{Design-based approach}
\end{center}
\begin{equation*}
deff=\frac{Var_c(\hat{t})}{Var_{srs}(\hat{t})}
\end{equation*}

<<>>=
var.tot.srs <- var(bm$Tot04)/30*(1-30/nrow(bm))*nrow(bm)^2
deff <- var.HT.tot.samp/var.tot.srs
deff
@
\begin{itemize}
\item Although the sample has been drawn with unequal probabilities, the design effect is below 1
\item[$\Rightarrow$] Highly correlated variable has been used to calculate the inclusion probabilities 
\end{itemize}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Design Effects}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Design Effects}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Model-based approach}
\end{center}
\begin{equation*}
\hat{deff}=\hat{deff_p} * \hat{deff_c} = n\frac{\sum_{h=1}^ld_h^2 n_h}{(\sum_{h=1}^ld_h n_h)^2}*(1+(\overline{b}-1)\rho)
\end{equation*}

\begin{itemize}
\item[] \alert{$n_h$} is the number of units per cluster; \alert{$\overline{b}$} is the average cluster size; \alert{$\rho$} reflects the Intraclass Correlation Coefficient (ICC)
\pause\item[$\Rightarrow$] No cluster/ stratified random sample
\item[$\Rightarrow$] $deff_p$ captures the design effect due to unequal inclusion probabilities
\end{itemize}

<<>>=
deff_p <- sum(30*(1/pik[s==1])^2)/sum(1/pik[s==1])^2
deff_p
@
\pause\begin{center}
\textbf{Effective sample size}
\end{center}
\begin{equation*}
n_{eff}=\frac{n}{deff}
\end{equation*}
 
<<>>=
30/deff
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Calibration}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Calibration}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Poststratification}
\end{center}

Using the my.pop data set of day 1
<<echo=FALSE>>=
id <- 1:10000
set.seed(42)
education <- sample(c("none","low","average","high"),10000, 
                    replace = T,prob = c(.072,.356,.289,.283))

gender <- sample(c("male","female"),10000,
                 replace = T,prob = c(.488,.512))

iq <- rnorm(10000,100,20)
my.pop <- data.frame(id,gender,education,iq)
@
<<>>=
s <- srswor(100,10000)
samp <- my.pop[s==1,]
genXedu.s <- data.frame(table(samp$gender,samp$education))
genXedu.s[,3] <- genXedu.s[,3]/sum(genXedu.s[,3])
genXedu.pop <- data.frame(table(my.pop$gender,my.pop$education))
genXedu.pop[,3] <- genXedu.pop[,3]/sum(genXedu.pop[,3])
adj.w <- data.frame(genXedu.pop[,3]/genXedu.s[,3])
adj.w[,1]
samp$to.merge <- paste(samp$gender,samp$education)
adj.w$to.merge <- paste(genXedu.s$Var1,genXedu.s$Var2)
adjusted <- merge(adj.w,samp,by="to.merge")
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Calibration}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Calibration}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Raking/ Iterative Proportional Fitting}
\end{center}
Generating the necessary data frames
<<cache=T>>=
age <- rep(as.character(1:6),times=10)
edu <- rep(as.character(1:5),each=6,times=2)
gender <- rep(c("m","w"),each=30)
freq <- sample(100,60,replace=T)
# Synthetic sample distribution
samp <- data.frame(age,edu,gender,freq)
samp[,4] <- samp[,4]/sum(samp[,4])
freq2 <- sample(100,60,replace=T)
# in population
master <- data.frame(age,edu,gender,freq2)
master[,4] <- master[,4]/sum(master[,4])
masageXedu <- aggregate(master[,4],
                        list(age=master[,1],edu=master[,2]),sum)
masageXgen <- aggregate(master[,4],
                        list(age=master[,1],gender=master[,3]),sum)
maseduXgen <- aggregate(master[,4],
                        list(edu=master[,2],gender=master[,3]),sum)
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Calibration}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Calibration}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Raking/ Iterative Proportional Fitting}
\end{center}
\tiny{
<<>>=
w_0 <- rep(1,times=nrow(samp))
times <- 0
while(times <= 1000){
  #AgexEducation
  saxe <- aggregate(samp[,4]*w_0,list(age=samp[,1],edu=samp[,2]),sum)
  w_1 <- masageXedu[,3]/saxe[,3]
  w_1 <- rep(w_1,times=(nrow(samp)/nrow(saxe)))
  #AgexGender
  saxg <- aggregate(samp[,4]*w_0*w_1,list(age=samp[,1],gen=samp[,3]),sum)
  w_2 <- masageXgen[,3]/saxg[,3]
  w_2 <- c(rep(w_2[1:(length(w_2)/2)],times=(nrow(samp)/nrow(saxg))),
         rep(w_2[(length(w_2)/2+1):length(w_2)],times=(nrow(samp)/nrow(saxg))))
  #EducationxGender
  sexg <- aggregate(samp[,4]*w_0*w_1*w_2,list(edu=samp[,2],gen=samp[,3]),sum)
  w_3 <- maseduXgen[,3]/sexg[,3]
  w_3 <- rep(w_3,each=(nrow(samp)/nrow(sexg)))
  #w4
  w_4 <- w_0*w_1*w_2*w_3
  if(max(abs(w_0-w_4))>0.05)
          {w_0<-w_4
          times<-times+1}
  else {break}
  cat("iteration",times,"\n")
}
samp$weight<-w_0*samp[,4]
@
}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Calibration}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Calibration}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Raking/ Iterative Proportional Fitting}
\end{center}
<<>>=
sampeduXgen<-aggregate(samp[,5],list(edu=samp[,2],gen=samp[,3]),sum)
@
\begin{columns}
\begin{column}{.5\textwidth}
<<>>=
sampeduXgen
@
\end{column}
\begin{column}{.5\textwidth}
<<>>=
maseduXgen
@
\end{column}
\end{columns}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%{The survey package}%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{itemize}
\item The survey package provides a large range of applications for complex survey samples
\item Typically, the first step is to define a survey object with the \R{svydesign()} command
\end{itemize}
\begin{center}
\textbf{Simple survey object (single stage)}
\end{center}
<<cache=T>>=
library(Matrix)
library(survey)
bm$pik1 <- inclusionprobabilities(bm$Tot03,100)
s <- UPmaxentropy(bm$pik1)
samp <- getdata(bm,s)
IPkl <- UPmaxentropypi2(bm$pik1)
surv.obj <- svydesign(id=~1,fpc = samp$pik1,
               data = samp,pps = ppsmat(IPkl[s==1,s==1]),
               variance = "YG")
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
<<echo=T,eval=F>>=
surv.obj <- svydesign(id=~1,fpc = samp$pik1,
              data = samp,pps = ppsmat(IPkl[s==1,s==1]),
              variance = "YG")
@
}
\begin{itemize}
\item \R{id} specifies the identifier of PSU and SSU;\R{id$=$ \textasciitilde0} or \R{id$=$\textasciitilde1} stipulates a single stage sampling
\item For multi-stage samples the \R{id} argument should always specify a formula with the cluster-identifier at each stage
\item \R{fpc} should be used for the finite population correction
\item[$\Rightarrow$] Either as the total population size of each stratum or as a fraction of the total population that has been sampled 
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
<<echo=T,eval=F>>=
surv.obj <- svydesign(id=~1,fpc = samp$pik,
                data = samp,pps = ppsmat(IPkl[s==1,s==1]),
                variance = "YG")
@
}
\begin{itemize}
\item \R{data} reflects the data set for which the design object should be defined
\item \R{pps} should be used to define the design information that should be used; usually the second order probability of inclusion
\item[$\Rightarrow$] \R{ppsmat()} is a wrapper for the joint inclusion probabilities of the HT-Estimator
\item With \R{variance} you can specify whether you use the Yates-Grundy- or the HT-Estimator
\item[$\Rightarrow$] For fixed sample sizes, "YG" should be used
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Important commands}
\end{center}
\begin{tabular}{ll}
\R{svytotal} & returns the estimated total of a variable \\ & and its standard error ($+ deff$)\\
\R{svymean} & returns the estimated mean of a variable\\ & and its standard error ($+ deff$)\\
\R{svyquantile} & Computes quantiles for data from complex surveys\\
\R{svyvar} & Computes variances  for data from complex surveys\\
\R{weights} & Returns the (design) weights of a survey object\\
\R{calibrate} & Calibration of a data set (uses the GREG-Estimator)\\
... & ...\\
\end{tabular}

<<>>=
svytotal(~Tot04,surv.obj)
@
}
\end{frame}
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Example: changing the "YG" argument with fixed sample sizes}
\end{center}

<<>>=
surv.obj2 <- svydesign(id=~1,fpc = samp$pik,
             data = samp,pps = ppsmat(IPkl[s==1,s==1])
             ,variance = "HT")
svytotal(~Tot04,surv.obj2)
@
\begin{itemize}
\pause\item[$\Rightarrow$] The variance estimator under HT varies more than the ont of the YG estimator
\pause\item[$\Rightarrow$] In this case the estimator is negative
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Calibrating the sample}
\end{center}
\footnotesize{
The GREG-Estimator within the survey package}
<<>>=
svymean(~averageincome,surv.obj)
mean(bm$averageincome)
@
\begin{itemize}\footnotesize{
\item Using the variable Men03 and Arrondiss as auxiliary information 
\item Calculating the population Total}
\end{itemize}

<<>>=
lm1 <- lm(averageincome ~Men03+Arrondiss, data=bm)
pop.tot <- colSums(model.matrix(lm1))
@
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Calibrating the sample}
\end{center}

\begin{itemize}\footnotesize{
\item Calculation the calibration weights with the \R{calibrate()} command}
\end{itemize}

<<cache=T>>=
surv.obj3 <- svydesign(id=~0,fpc = samp$pik1,
                       data = samp,pps = "brewer")
@
\begin{itemize}
\item The \R{calibrate} function cannot be applied to the previous object of class "ppsmat"
\item[$\Rightarrow$] Therefore we use the brewer approximation for joint inclusion probabilities
\pause\item[$\Rightarrow$] Seems odd, since only first order inclusion probabilities are used for calibration
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Calibrating the sample}
\end{center}

<<>>=
g_i <- calibrate(surv.obj3,formula =~Men03+Arrondiss
                 ,population=pop.tot,calfun="linear")
@
\begin{itemize}
\item The names of the variables that are used for the calibration have to be identical for your survey object and your population
\item \R{formula} specifies the calibration model
\item With \R{calfun} you can choose between a linear model (GREG) or a raking approach
\item For only one calibration variable, \R{calibrate} produces the same weights as a poststratification
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\vspace{-.25cm}
\begin{center}
\textbf{Calibration results}
\end{center}
\footnotesize{
\vspace{.25cm}
\begin{columns}
\begin{column}{.5\textwidth}
\begin{block}{Sample}
<<>>=
svymean(~averageincome,g_i)
svytotal(~Men03,g_i)
svytotal(~Arrondiss,g_i)
@
\end{block}
\end{column}
\begin{column}{.5\textwidth}
\vspace{-1cm}
\begin{block}{Population}
<<>>=
mean(bm$averageincome)
sum(bm$Men03)
sum(bm$Arrondiss)
@
\end{block}
\end{column}
\end{columns}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\vspace{-.25cm}
\begin{center}
\textbf{Multi-stage samples}
\end{center}
\footnotesize{
Loading the \R{api} data set and generating a \emph{multi-stage} data frame

<<cache=T>>=
data(api)
score <- by(apiclus1,apiclus1$cds,
        function(x)rnorm(x$api.stu,mean = x$api00, sd = sqrt(x$api00)))
@

\begin{itemize}
\item the \R{by} command is similar to \R{tapply} and creates a list of normal distributed test scores for each school 
\end{itemize}

<<cache=T>>=
l <- 50
nh <- 60
apiclus1$fpc <- inclusionprobabilities(apiclus1$enroll,l)
@

\begin{itemize}
\item We draw a sample of $l=50$ schools (PSUs) proportional to the number of enrolled pupils
\end{itemize}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Sampling the cluster}
\end{center}

<<cache=T>>=
cs <- UPmaxentropy(apiclus1$fpc)
cs.dat <- apiclus1[cs==1,]
@

\vspace{.5cm}
\begin{center}
\textbf{Sampling within a school}
\end{center}

<<cache=T>>=
score.cs.dat <- score[as.character(cs.dat$cds)]
score.samp <- lapply(score.cs.dat,function(x)x[sample(length(x),nh)])
names(score.samp) <- names(score.cs.dat)
data.s <- data.frame(score = unlist(score.samp),
          cds=rep(names(score.samp),
                  times=sapply(score.samp,length)))
@

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The survey package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{The survey package}\end{center}}
\vspace{-.25cm}
\footnotesize{
\begin{center}
\textbf{Merging the data sets/ Second stage inclusion probabilities}
\end{center}

<<cache=T>>=
DATA.s <- merge(cs.dat,data.s,by="cds")
DATA.s$id <- 1:nrow(DATA.s)
DATA.s$fpc2 <- nh/DATA.s$enroll
@

\begin{itemize}
\item[$\Rightarrow$] Full sample of 50 PSUs with 60 SSUs each
\item[$\Rightarrow$] \emph{Self-weighting} approach
\end{itemize}

\pause\begin{center}
\textbf{Specifying the survey object}
\end{center}

<<>>=
mul.surv <- svydesign(id=~cds+id,fpc = ~fpc+fpc2,
                      data=DATA.s, pps="brewer")
svymean(~api00,mul.surv)
table(weights(mul.surv))
@

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Exercise 4}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Exercise 4}\end{center}}
\footnotesize{
\begin{exampleblock}{Design effects/ One-stage cluster sample}
\begin{enumerate}\footnotesize{
\item Draw a sample of $l=20$ FULL arondissments proportional to the population of 2003
\begin{itemize}
\item[$\Rightarrow$] Use the maximum entropy algorithm
\end{itemize}
\item Calculate the design effect by the model based approach
\begin{block}{Model based approach}
\begin{equation*}
\hat{deff}=\hat{deff_p} * \hat{deff_c} = n\frac{\sum_{h=1}^ld_h^2 n_h}{(\sum_{h=1}^ld_h n_h)^2}*(1+(\overline{b}-1)\rho)
\end{equation*}
\begin{equation*}
\hat{\rho}^{AOV}=\frac{MSB-MSW}{MSB+(K-1)MSW}
\end{equation*}
\begin{equation*}
MSB=\frac{SSB}{l-1}\text{;~~~~~~~}MSW=\frac{SSW}{n-l}\text{;~~~~~~~}K=\frac{1}{l-1}(n-\sum_{h=1}^l\frac{n_h^2}{n})
\end{equation*}
\end{block}
}
\end{enumerate}
\end{exampleblock}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Exercise 4}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Exercise 4}\end{center}}
\footnotesize{
\begin{exampleblock}{Design effects/ One-stage cluster sample}
\begin{enumerate}\footnotesize{
\begin{block}{R-code MSW/ MSB}
<<echo=T,eval=F>>=
### MSW and MSB 
SS <- anova(lm(DATA.c$Tot04~DATA.c$Arrondiss))
MSB <- SS$`Mean Sq`[1]
MSW <- SS$`Mean Sq`[2]
@
\end{block}
\item[3] Calculate deff under the design based approach
\item[4] Calculate the effective sample size}
\end{enumerate}
\end{exampleblock}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Exercise 5}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Exercise 5}\end{center}}
\footnotesize{
\begin{exampleblock}{The survey package/ Multi-stage sampling}
\begin{enumerate}
\item Create the normal distributed income for each individual in 2004 within each commune of the belgianmunicipalities data set (use the square root of the average income as the standard deviation)
\item Draw a sample of $l=50$ communes (use the INS as identifier) proportional to the population of 2003
\item Draw a sample of $n_h=80$ individuals within each commune
\item Estimate the mean income of your sample (design weighted)
\item Poststratify your data set to the number of men in 2003
\end{enumerate}
\end{exampleblock}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%












\end{document}