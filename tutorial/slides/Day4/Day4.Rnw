\documentclass[11pt,german,hideothersubsections]{beamer}

\usepackage{hyperref}
\usepackage{amsmath,nicefrac,booktabs,mathabx}
\usepackage{natbib}
\usepackage{url}
\usepackage{textpos}
\usepackage{listings}
\definecolor{Rblau}{rgb}{.3,.6,.9}

\lstset{language=R,
        basicstyle=\ttfamily\footnotesize,
        keywordstyle=\color{blue}\bfseries,
        identifierstyle=\color{Rblau},
        commentstyle=\color{gray},
        stringstyle=\color{green}\ttfamily,
        showstringspaces=false,
        frame=tb}



\bibpunct{(}{)}{;}{a}{,}{,}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{helvet}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow,dcolumn}
\usepackage{ragged2e}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{tikz}
\usetikzlibrary{calc}
\usepackage{booktabs}
\colorlet{tablesubheadcolor}{gray!25}
\colorlet{tableheadcolor}{gray!40}
\colorlet{tablerowcolor}{gray!15.0}
\usetheme[english]{Gesis}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]%{\hspace*{.2cm}\insertframenumber}
\setbeamerfont{caption}{size=\footnotesize}
\usefonttheme[onlylarge]{structuresmallcapsserif} % alte Schrift

\newcommand{\R}[1]{{\tt \color{blue}  #1}}
\newtheorem{thm}{Theorem}
\newtheorem{rem}{Bemerkung}
\newtheorem{lem}{Lemma}

\definecolor{hellgrau}{rgb}   {0.109375,  0.40625,   0.51953125}
\definecolor{dunkelgrau}{rgb} {0.009375,  0.30625,   0.41953125}
\definecolor{dunkelgrau2}{rgb}{0.009375,  0.20625,   0.31953125}
\definecolor{hellbraun}{rgb}  {0.9140625, 0.8984375, 0.8046875}
\definecolor{hellbraun2}{rgb} {.95,       0.9,       0.8}
\definecolor{alertred}{rgb}   {0.8515625, 0.3828125, 0.08984375}
\definecolor{orange}{rgb}{1,0.5,0}


\setbeamercolor{firstsecslide}{fg=white,bg=dunkelgrau}
\setbeamertemplate{blocks}[rounded][shadow=true]

\newcolumntype{d}[0]{D{,}{.}{6}}

\newenvironment{itemizeol}{\begin{itemize}[<+->]}{\end{itemize}}
\newenvironment{descriptionol}{\begin{description}[<+->]}{\end{description}}

\newcolumntype{V}[1]{%
  >{\RaggedRight\hspace{0pt}}p{#1}%
}

\newcommand{\emphred}[1]{\textcolor{alertred}{#1}}
\newcommand{\emphcol}[1]{\textcolor{dunkelgrau}{\slshape #1}}

\setcounter{tocdepth}{1}
\setbeamercolor*{section in toc}{fg=hellgrau}
\setbeamertemplate{bibliography item}[default]
\makeatother
\addtobeamertemplate{frametitle}{}{%
\begin{textblock*}{100mm}(.91\textwidth,-1cm)
\includegraphics[height=1cm,width=2cm]{../../graphs/logos/GESIS_Logo_kompakt_en.jpg}
\end{textblock*}}

\title[Day 1]{Tutorial: Sampling, Weighting and Estimation\\ \Large{Day 4} }
%\subtitle{Umgang am Beispiel von Telefonstichproben}

\author[M. Sand]{Stefan Zins, Matthias Sand\\ and Jan-Philipp Kolb\\ \vspace{.5cm} \footnotesize{GESIS - Leibniz Institute\\ for the Social Sciences}}
%\institute{\includegraphics[width=4.5cm]{GESIS_Logo_informell}}
\date[]{\color{dunkelgrau}\footnotesize%
\begin{minipage}{8cm}%
\begin{center}%
\scriptsize{
\textbf{GESIS Summer School}\\ \tiny{Cologne, Germany}%
}\\
\vspace{0.25cm}
\textbf{August 27th, 2015}%

\end{center}%
\end{minipage}}%


\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle
<<t,echo=F,eval=T>>=
options(prompt = " ")
options(digits=4)
#library(knitr)
library(sampling)
library(survey)
library(Matrix)
data(api)
data("belgianmunicipalities")
bm<-belgianmunicipalities
CA<-T
Ex<-T
set.seed(42)
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Usefull Commands} {of the Survey Package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\vspace{-.25cm}
\begin{center}
\textbf{Computation of contrasts}
\end{center}
<<echo=F,eval=T>>=
score <- by(apiclus1,apiclus1$cds,
        function(x)rnorm(x$api.stu,mean = x$api00, sd = sqrt(x$api00)))
l <- 50
nh <- 60
apiclus1$fpc <- inclusionprobabilities(apiclus1$enroll,l)
cs <- UPmaxentropy(apiclus1$fpc)
cs.dat <- apiclus1[cs==1,]
score.cs.dat <- score[as.character(cs.dat$cds)]
score.samp <- lapply(score.cs.dat,function(x)x[sample(length(x),nh)])
names(score.samp) <- names(score.cs.dat)
data.s <- data.frame(score = unlist(score.samp),
          cds=rep(names(score.samp),
                  times=sapply(score.samp,length)))
DATA.s <- merge(cs.dat,data.s,by="cds")
DATA.s$id <- 1:nrow(DATA.s)
DATA.s$fpc2 <- nh/DATA.s$enroll
mul.surv <- svydesign(id=~cds+id,fpc = ~fpc+fpc2,strata=NULL,
                      data=DATA.s, pps="brewer")
@
\begin{itemize}
\item Using the multi-stage sample of day 3 (\R{mul.surv})
\end{itemize}
<<>>=
means <-svymean(~api00+api99,mul.surv)
means
svycontrast(means,quote(api00-api99))
@
\begin{itemize}
\item The command \R{svycontrast()} can be used to estimate contrasts for linear and nonlinear survey statistics and their standard error
\end{itemize}
<<>>=
svycontrast(means,quote(api00/api99))
@
\begin{itemize}
\item[$\Rightarrow$] \R{svyratio(\textasciitilde0 api00,\textasciitilde0 api99,mul.surv)} generates the same results
\end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Usefull Commands} {of the Survey Package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Weighted regression}
\end{center}
\scriptsize{
<<>>=
summary(svyglm(api00~enroll+meals+api99,mul.surv))
@
}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Usefull Commands} {of the Survey Package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Weighted regression}
\end{center}

<<eval=FALSE>>=
summary(svyglm(api00~enroll+meals+api99,mul.surv))
@

\begin{itemize}\footnotesize{
\item The \R{svyglm()} function fits linear and generalized lin. models to the data stored in a survey object 
\item syntax almost identical to the glm, except that the data argument is replaced by a design argument $\rightarrow$ weighted least square
\item Main difference to \R{glm()}: \R{svyglm()} doe not use a maximum likelihood approach}
\end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Usefull Commands} {of the Survey Package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Survey weighted contingency tables and chi squared tests}
\end{center}
<<>>=
tab1 <- svytable(~stype+sch.wide,mul.surv)
tab1
@
\begin{itemize}\footnotesize{
\item Creates the weighted contingency table of two or more variables}
\end{itemize}\footnotesize{

<<cache=T>>=
plot(tab1, col="blue",xlab = "school type", 
     ylab = "growth target",cex.lab=0.25)
@
}
\begin{itemize}
\item Such contingency tables can easily be visualized to learn more about the sampled variables
\end{itemize}

}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Usefull Commands} {of the Survey Package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Survey weighted contingency tables and chi squared tests}
\end{center}

<<fig=T,height=4,echo=FALSE>>=
plot(tab1, col="blue",xlab = "school type", 
     ylab = "growth target",main="Met school-wide target")
@

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Usefull Commands} {of the Survey Package}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Survey weighted contingency tables and chi squared tests}
\end{center}
\vspace{.25cm}
<<>>=
chi <- svychisq(~stype+sch.wide,mul.surv,statistic="adjWald")
chi
@
}

\begin{itemize}\footnotesize{
\item Tests for the association of sample variables
\item Numerous tests are applicable
\item In this case it is tested for independence under the consideration of the number of PSUs}
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Usefull Commands} {of the Survey Package}
\footnotesize{
\begin{center}
\textbf{Estimation of subpopulations}
\end{center}
\begin{itemize}
\footnotesize{
\item Within a stratified random sample, subtotals for each stratum are easy to compute, since every stratum can be treated like a separate srs
\pause\item For an unstratified design or subpopulations that are no strata, the situation is more complicated, since the joint inclusion probabilities $\pi_{kl}$ are unequal to those that would be, if this group had been a stratum
\item Sampling weights would be correct, but pairwise sampling probability would be incorrect
\pause\item[$\Rightarrow$] Unbiased point estimates; but standard errors would be wrong
}
\end{itemize}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Usefull Commands} {of the Survey Package}
\footnotesize{
\begin{center}
\textbf{Estimation of subpopulations}
\end{center}
\begin{itemize}
\footnotesize{
\item The survey package deals with these problems without any further specification as long as the full sample is used to define a survey object
\item Subpopulations either by \R{subset} or \R{svyby}
}
\end{itemize}
<<>>=
sub1 <- subset(mul.surv,sch.wide=="Yes")
svymean(~api00+api99,sub1)
sub2 <- svyby(~api00,~stype,svymean,design = mul.surv)
print(sub2)
@

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Taylor Linearization} {with the ratio estimator}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{The ratio estimator}
\end{center}
\begin{equation*}
\frac{\hat{t}_{y,HT}}{\hat{t}_{x,HT}}
\end{equation*}
\begin{itemize}
\item Drawing a sample of $n=130$ from bm
\end{itemize}
<<>>=
bm$pik <- inclusionprobabilities(bm$Tot03,130)
s <- UPmaxentropy(bm$pik)
ratioest(y=bm$TaxableIncome[s==1],x=bm$averageincome[s==1],
         Tx=sum(bm$averageincome),pik=bm$pik[s==1])
@

\begin{itemize}
\item Returns the ratio estimator of the population total
\item[$\Rightarrow$] Another way to calculate the ratio estimator is implemented in the survey package
\end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Taylor Linearization} {with the ratio estimator}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{The ratio estimator}
\end{center}
<<>>=
samp <- bm[s==1,]
IPkl <-UPmaxentropypi2(bm$pik)
obj <- svydesign(id=~1,fpc = ~pik,data=samp,
                 pps = ppsmat(IPkl[s==1,s==1]),variance="YG")
svyratio(~TaxableIncome,~averageincome,obj)
@
\begin{itemize}
\item The \R{svyratio()} command returns the ratio between the two weighted sampling variables.
%\item[$\Rightarrow$] To obtain an estimator for the total, the ratio must be multiplied with the populatiopn total of the auxiliary variable
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Taylor Linearization} {with the ratio estimator}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{The ratio estimator}
\end{center}
\begin{itemize}
%\item The \R{svyratio()} command returns the ratio between the two weighted sampling variables.
\item To obtain an estimator for the total, the ratio must be multiplied with the population total of the auxiliary variable
\end{itemize}

<<>>=
as.numeric(svyratio(~TaxableIncome,~averageincome,obj))*
  sum(bm$averageincome)
@

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Taylor Linearization} {with the ratio estimator}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Variance estimation}
\end{center}
\begin{itemize}
\item Estimating the Variance of the ratio estimator via \emph{Taylor Linearization} with the sampling package
\end{itemize}
\scriptsize{
<<>>=
vartaylor_ratio(Ys=samp$TaxableIncome,Xs=samp$averageincome,
                pikls = IPkl[s==1,s==1])
@
<<echo=F,eval=T>>=
sqrt(vartaylor_ratio(Ys=samp$TaxableIncome,Xs=samp$averageincome,
                pikls = IPkl[s==1,s==1])$estvar)
@
}
\begin{itemize}
\pause\item The survey package uses \emph{Taylor Linearization} by default to estimate standard errors based on design information
\pause\item The \R{vartaylor\_ratio()} returns the HT-estimator of the variance, not the YG-type
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Replicate Weights}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{itemize}
\item Within the survey package all of the \emph{common} strategies are implemented and easy to use
\item First step: redefine the survey object as a replicate weights object with the \R{as.svrepdesign()} command
\item Second step: choosing a strategy with the \R{type=} argument
\pause\item[$\Rightarrow$] Most of the strategies cannot create replicate weights under unequal inclusion probabilities and resample only the PSUs to create replicate weights
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Replicate Weights}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Jackknife}
\end{center}
<<>>=
dclus1 <- svydesign(id=~dnum,weights=~pw,data=apiclus1,
                    fpc= rep(757/15,times=nrow(apiclus1)))
clus.rep <- as.svrepdesign(dclus1,type = "JK1")
svyquantile(~api00 , clus.rep, c (.25 ,.5 ,.75) ,
            interval.type ="probability")
@
\begin{itemize}
\item Allows the estimation of standard errors for quantiles, etc.
\item In case of estimates for the totals and means, the estimates for the standard error are comparable to those of the Taylor Linearization
\item \R{"auto"} as \R{type}-argument uses JKn for stratified and JK1 for unstratified samples
\end{itemize}


}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Replicate Weights}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Bootstrap}
\end{center}
<<>>=
rep.clus2 <- as.svrepdesign(dclus1,type = "bootstrap",
                            replicates = 100)
svyquantile(~api00,rep.clus2,c (.25 ,.5 ,.75) ,
            interval.type ="probability")
@
\begin{itemize}
\item[$\Rightarrow$] Reduces the standard error
\item design weights are the starting weights multiplied by the times they have been sampled within each iteration (srswr!)
\end{itemize}
}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Replicate Weights}
%\frametitle{\vspace{-.05cm}\begin{center}\footnotesize{Usefull Commands of the Survey Package}\end{center}}
\footnotesize{
\begin{center}
\textbf{Balanced Repeated Replicates (BRR)}
\end{center}
\begin{itemize}
\item BRR is appealing because it requires less computational effort than the Jackknife method
\item BRR standard errors are valid for quantiles and median, while the Jackknife method might produce invalid results
\end{itemize}

\scriptsize{
<<>>=
dstrat <- svydesign(id=~1,weights=~pw,strata = ~stype,
                    data = apistrat,fpc = ~fpc) 
rep3 <- as.svrepdesign(dstrat,type = "BRR")
svyquantile(~api00,rep3,c (.25 ,.5 ,.75) ,
             interval.type ="probability")
@
}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Replicate Weights}
\footnotesize{
\begin{center}
\textbf{Summary: replicate weights and single stage sampling}
\end{center}
\begin{itemize}
\item All three methods can only be applied to single-stage samples or resample only on the PSU-level
\item All three approaches ignore the fpc
\pause\item Bootstrap is only straightforward, when all strata sizes are large
\pause\item The BRR approach yields the smallest estimates for the standard error, but has difficulties when dealing with cluster samples
\pause\item[$\Rightarrow$] BRR can only be applied for samples with two clusters per stratum
\pause\item[$\Rightarrow$] All three approaches have problems with multi-stage samples and unequal inclusion probabilities 

\end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Replicate Weights}
\footnotesize{
\begin{center}
\textbf{Multi-stage samples and replicate weights}
\end{center}
\begin{itemize}
\item In case of multi-stage samples, the \emph{mrb} or \emph{mrbbootstrap} method of Preston should be employed
\item[$\Rightarrow$] Resamples PSUs and SSUs rather than only PSUs
\end{itemize}
\tiny{
<<>>=
summary(svyglm(api00~enroll+meals+api99,mul.surv))
@
}

}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Replicate Weights}
\footnotesize{
\begin{center}
\textbf{Multi-stage samples and replicate weights}
\end{center}
\tiny{
<<>>=
rep4 <- as.svrepdesign(mul.surv,type = "mrbbootstrap")
summary(svyglm(api00~enroll+meals+api99,rep4))
@
}
\begin{itemize}\scriptsize{
\item Reduces standard error of the estimates
\item Estimates are far more significant
\item Needs more computational time then other resampling strategies
\item[$\Rightarrow$] But: correct approach for multi-stage samples}
\end{itemize}
}
\end{frame}



% apiclus1.  <- apiclus1[!(apiclus1$dnum%in%c(716,413)),]
% apiclus1.$fpc  <- length(unique(apipop$dnum))
% apiclus1.$fpc2 <- table(apiclus1.$dnum)[as.character(apiclus1.$dnum)]
% 
% nh<-round(table(apiclus1.$dnum)/nrow(apiclus1.) *40)
% test <- mapply(function(x,y)sample(as.character(x),y),split(apiclus1.$cds,apiclus1.$dnum)[names(nh)],nh)
% apiclus1.2 <- apiclus1.[apiclus1.$cds%in%unlist(test),]
% 
% vs1 <- svydesign(id=~dnum+cds,fpc=~fpc+fpc2, data = apiclus1.2)
% 
% vs2 <-as.svrepdesign(vs1,type="mrb")
% 
% 
%' <<>>=
%' sv2 <- as.svrepdesign2(mul.surv,type="mrbbootstrap")
%' a<-hadamard(2)
%' @
%' 
%' sv2 <- as.svrepdesign2(mul.surv,type="mrbbootstrap")
%' % summary(svyglm(api00~enroll+meals+api99,sv2))
%' 
%' 
%' summary(svyglm(api00~enroll+meals+api99,sv2))






























































\end{document}