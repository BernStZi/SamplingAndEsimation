%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[10pt]{beamer}
\usepackage{etex}

\usepackage[T3,T1]{fontenc}
\usepackage{textpos} 
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amsfonts,nicefrac,mathabx,amssymb,amsbsy,bbm}
\usepackage[subnum]{cases}
\usepackage{calligra, mathrsfs}
%\usepackage{natbib}
\usepackage{booktabs}
%\bibpunct{(}{)}{;}{a}{,}{,}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{helvet}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow,dcolumn}
\usepackage{listings}
\usepackage{ragged2e}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{animate} %for animated graphs
\usepackage{graphicx}
\usepackage{url}
\usepackage{bibentry}
\usepackage{chngcntr}

\ifx\hypersetup\undefined
  \AtBeginDocument{%
    \hypersetup{unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},backref=false,colorlinks=false}
  }
\else
  \hypersetup{unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},backref=false,colorlinks=false}
\fi
\DeclareSymbolFont{tipa}{T3}{cmr}{m}{n}
\DeclareMathAccent{\invbreve}{\mathalpha}{tipa}{16}


\colorlet{tablesubheadcolor}{gray!25}
\colorlet{tableheadcolor}{gray!40}
\colorlet{tablerowcolor}{gray!15.0}
\usetheme{Gesis}
%\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]%{\hspace*{.2cm}\insertframenumber}
\setbeamerfont{caption}{size=\footnotesize}
\usefonttheme[onlylarge]{structuresmallcapsserif} % alte Schrift


\definecolor{hellgrau}{rgb}   {0.109375,  0.40625,   0.51953125}
\definecolor{dunkelgrau}{rgb} {0.009375,  0.30625,   0.41953125}
\definecolor{dunkelgrau2}{rgb}{0.009375,  0.20625,   0.31953125}
\definecolor{hellbraun}{rgb}  {0.9140625, 0.8984375, 0.8046875}
\definecolor{hellbraun2}{rgb} {.95,       0.9,       0.8}
\definecolor{alertred}{rgb}   {0.8515625, 0.3828125, 0.08984375}
\definecolor{orange}{rgb}{1,0.5,0}


\setbeamercolor{firstsecslide}{fg=white,bg=dunkelgrau}
\setbeamertemplate{blocks}[rounded][shadow=true]

\newcolumntype{d}[1]{D{.}{.}{#1}}

\newcommand{\emphred}[1]{\textcolor{alertred}{#1}}
\newcommand{\emphcol}[1]{\textcolor{dunkelgrau}{\slshape #1}}

\newcommand{\eqname}[1]{\tag*{#1}} %equation title

\newenvironment{frcseries}{\fontfamily{frc}\selectfont}{}
\newcommand{\textfrc}[1]{{\frcseries#1}}
\newcommand{\mathfrc}[1]{\text{\textfrc{#1}}}


\setcounter{tocdepth}{1}
\setbeamercolor*{section in toc}{fg=hellgrau}
\setbeamertemplate{bibliography item}[default]


\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\newsavebox{\mysavebox}


\newcommand{\E}[1]{\text{E}\left(#1\right)}
\newcommand{\V}[1]{\text{V}\left(#1\right)}
\newcommand{\Vest}[1]{\widehat{\text{V}}\left(#1\right)}
\newcommand{\MSE}[1]{\text{MSE}\left(#1\right)}
\newcommand{\COV}[2]{\text{COV}\left(#1,\,#2\right)}
\newcommand{\deff}{\ensuremath{\text{\slshape deff}}}
%roman numbers in equation
\newcommand{\RN}[1]{%
  \textup{\uppercase\expandafter{\romannumeral#1}}%
}
\newcommand{\deffhat}{\ensuremath{\widehat{\text{\slshape deff}}}}
\newcommand{\deffc}{\ensuremath{\text{\slshape deff}_{\text{\slshape c}}}}
\newcommand{\deffhatc}{\ensuremath{\widehat{\text{\slshape deff}}_{\text{\slshape c}}}}
\newcommand{\deffp}{\ensuremath{\text{\slshape deff}_{\text{\slshape p}}}}
\newcommand{\neff}{\ensuremath{n_\text{\slshape eff}}}
\newcommand{\nnet}{\ensuremath{n_\text{\slshape net}}}
\newcommand{\ngross}{\ensuremath{n_\text{\slshape gross}}}


\makeatletter

\addtobeamertemplate{frametitle}{}{%
\begin{textblock*}{100mm}(.91\textwidth,-1cm)
\includegraphics[height=1cm,width=2cm]{graphs/logos/GESIS_Logo_kompakt_en.jpg}
\end{textblock*}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
% this default might be overridden by plain title style
 \newcommand\makebeamertitle{\frame{\maketitle}}%
 % (ERT) argument for the TOC
 \AtBeginDocument{%
   \let\origtableofcontents=\tableofcontents
   \def\tableofcontents{\@ifnextchar[{\origtableofcontents}{\gobbletableofcontents}}
   \def\gobbletableofcontents#1{\origtableofcontents}
 }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%\usetheme{Montpellier}%\usetheme{PaloAlto}

\makeatother

\begin{document}
<<setup, include=FALSE>>=
library(PracTools) 
library(knitr)
library(xtable)
library(plyr)
library(survey)
library(sampling)
library(Matrix)
opts_chunk$set(fig.path='graphs/beamer-',fig.align='center',fig.show='hold',size='footnotesize')
@


\title[Variance Estimation]{4. GESIS Summer School in Survey Methodology
Cologne. Course 16: Sampling, Weighting and Estimation} 
\subtitle{Day 4: Linearization Methods for Variance Estimation}

\author{Stefan Zins\thanks{\href{mailto:Stefan.Zins@gesis.org}{Stefan.Zins@gesis.org}} and Matthias Sand\thanks{\href{mailto:Matthias.Sand@gesis.org}{Matthias.Sand@gesis.org}}}
\date{Thursday, August 27, 2015} 

\makebeamertitle


\section{Preliminary comments}
\begin{frame}
\frametitle{Preliminary comments on variance estimation}
\uncover<1-4>{In practice design based variance estimation will \emph{not} be an option for most surveys.} \uncover<2-4>{Why?} \uncover<3-4>{We do not know the $\pi_{kl}$ and in some cases not even the $\pi_k$
and even if we would, the response process and frame imperfections remain still unknown.}
\uncover<4>{
Thus we have to resort to second best solutions:
\begin{itemize}
\item Model based estimation (as shown for the estimation of the $\deff$)
\item Estimation of approximated variances
\end{itemize}
}
\uncover<5->{What exactly has variance estimation to fulfill?
\begin{itemize}
\item Deliver adequate quality measures
\item Consider practical issues
\end{itemize}}
\uncover<6->{But
\begin{itemize}
\item Can we apply general methods like for point estimation?
%\item Do we encounter contradictions in optimizing strategies between point and variance estimators?
\end{itemize}}
\end{frame}


\begin{frame}{Methods for Variance Estimation}
In variance estimation we face often following obstacles:
\begin{itemize}
\item<1-> Non-linear Statistics
\item<2-> Complex Designs (incl. non-response)
\end{itemize}

\uncover<3->{
Two of the commonly used methods to overcome these are
\begin{description}
\item<4->[Linearization]; An approximation to the variance of the estimator is sought that is far easier to estimate.
\item<5->[Resampling Methods]; The distribution of the estimator is simulated in order to estimate its variance.
\end{description}
} 
\uncover<6->{The line between model and design based approaches is not so clear in some cases.
There are resampling methods and linearization techniques that assume infinite population,  i.e.  they rely on models. We try to stay with the finite population \emph{model}.
}
\end{frame}




\begin{frame}
\frametitle{Recall StrSRS}
\onslide*<1-3>{
In StrSRS we have the variance and variance estimator:
\begin{align*}
  \V{\overline{y}_{\text{str}}}_{\text{SRS}} & = \sum_{h=1}^H \dfrac{N_h-n_h}{N_h} \gamma_h^2 \dfrac{V_{h}^2}{n_h} \\
  \Vest{\overline{y}_{\text{str}}}_{\text{SRS}} & = \sum_{h=1}^H \dfrac{N_h-n_h}{N_h} \gamma_h^2 \dfrac{s_{h}^2}{n_h} 
  \end{align*}
  \begin{equation*}
  s^2_{h} = \dfrac{1}{n_h-1} \sum_{k \in \mathfrc{s}_h} (y_k - \overline{y}_h)^2
\end{equation*}
}\uncover<2->{Most surveys in the social science use designs without replacement, thus even for SRS within strata we need to know the $N_h$, which are often not readily provided (e.g. for reasons of disclosure control). 
} \uncover<3->{ One approach would be to use the variance estimator for sampling with replacement instead:
 $$\Vest{\overline{y}_{\text{str}}}_{\text{SRSWR}}  = \sum_{h=1}^H \gamma_h^2 \dfrac{s_{h}^2}{n_h}$$
}\uncover<4->{Since  $\V{\overline{y}_{\text{str}}}_{\text{SRS}} \leq \V{\overline{y}_{\text{str}}}_{\text{SRSWR}}\;{.}$ we would on average over estimate the variance and thus have over conservative test results. \newline
(Note: $\E{s^2_{h}}_{SRS}$ > $\E{s^2_{h}}_{SRSWR}$, but this effect should be smaller than that of the neglected
finite population correction. )
}

\end{frame}
% 
% 
\begin{frame}
\frametitle{Recall the HT Estimator}
\onslide*<1>{
\begin{align*}
 \V{ \hat{\tau}_{\pi}}  &= \sum_{k \in \mathcal{U}} \sum_{l \in \mathcal{U}} \left( \pi_{kl} - \pi_k \pi_l \right)
\dfrac{y_k}{\pi_k}\dfrac{y_l}{\pi_l}  = (\breve{\mathbf{y}})^\top  \boldsymbol\Delta \breve{\mathbf{y}} \; {\text{and}} \\
\Vest{ \hat{\tau}_{\pi}}_1 &= \sum_{k \in \mathfrc{s}} \sum_{l \in \mathfrc{s}} \dfrac{\left( \pi_{kl} - \pi_k \pi_l \right)}{\pi_{kl}} \dfrac{y_k}{\pi_k}\dfrac{y_l}{\pi_l} =  (\breve{\mathbf{y}}_s)^\top  \breve{\boldsymbol\Delta}_s  \breve{\mathbf{y}}_s\;{,}
\end{align*}
where $\boldsymbol\Delta=[\pi_{kl}-\pi_k\pi_l]_{k,l \in \mathcal{U} }$,
$\breve{\mathbf{y}}=[y_{k}\pi_k^{-1}]_{k,l \in \mathcal{U} }$ and their sample equivalents are
$\breve{\boldsymbol\Delta}_s=[\frac{\pi_{kl}-\pi_k\pi_l}{\pi_{kl}}]_{k,l \in \mathfrc{s} }$ and
$\breve{\mathbf{y}}_s=[y_{k}\pi_k^{-1}]_{k,l \in \mathfrc{s} }$.}

\onslide*<2->{ For a fixed size design we may write the variance of $\hat{\tau}_{\pi}$ as
\begin{align*}
 \V{ \hat{\tau}_{\pi}} = - \dfrac{1}{2} \sum_{k \in \mathcal{U}} \sum_{l \in \mathcal{U}} \left( \pi_{kl} - \pi_k \pi_l \right) \left(\dfrac{y_k}{\pi_k} - \dfrac{y_l}{\pi_l}\right)^2 \;,
\end{align*}
which can be estimated by
\begin{align*}
 \Vest{ \hat{\tau}_{\pi}}_2 = - \dfrac{1}{2} \sum_{k \in \mathfrc{s}} \sum_{l \in \mathfrc{s}} \dfrac{\left( \pi_{kl} - \pi_k \pi_l \right)}{\pi_{kl}} \left(\dfrac{y_k}{\pi_k} - \dfrac{y_l}{\pi_l}\right)^2 \;.
\end{align*}

Note that $\Vest{ \hat{\tau}_{\pi}}_1 =\Vest{ \hat{\tau}_{\pi}}_2  + (\breve{\mathbf{y}}_s^2)^\top\breve{\boldsymbol\Delta}_s \mathbf{1}_s$, where  $\mathbf{1}_s$ is a vector of ones of length $n$. Hence, $\V{\Vest{ \hat{\tau}_{\pi}}_1} \geq \V{\Vest{ \hat{\tau}_{\pi}}_2}$, thus $\Vest{ \hat{\tau}_{\pi}}_1$ should never be used for fixed size designs.
}
\end{frame}

 \begin{frame}{Practical Estimators for  \\ the Design Variance}
\onslide*<1>{
Due to the double sum and the required knowledge of the $\pi_{kl}$'s, both variance estimators  $\Vest{ \hat{\tau}_{\pi}}_2$  and  $\Vest{ \hat{\tau}_{\pi}}_1$ are in practice not really applicable.
 In order to avoid calculating these double sums and the $\pi_{kl}$'s, several approximations have been proposed for a single sum variance estimator:
  \begin{align*}
	\Vest{\hat{\tau}_{\pi}}_{\text{approx}} = \sum_{k \in \mathfrc{s}} \hat{b}_k \hat{e}_k^2 \;{,}
\end{align*}
where
\begin{align*}
\hat{e}_k =& \, \dfrac{y_k}{\pi_k} - \hat{B} &\text{and} &	\quad \hat{B} = \dfrac{\sum_{k\in \mathfrc{s}}
\frac{y_k}{\pi_k}  \hat{b}_k}{\sum_{k \in \mathfrc{s}} \hat{b}_k }  \pi_k\;{.}
\end{align*}
}\onslide*<2>{
Numerous choices can be found in the literature for $\hat{b}_k$ [Matei \& Till\'{e}, 2005]:
\begin{align*}
	{}_{1}\hat{b}_k & = (1 - \pi_k) \dfrac{n}{n-1} \eqname{[H\'{a}jek, 1981]} \,{,} \\
	{}_{2}\hat{b}_k & = (1 - \pi_k) \left[1- \sum_{k \in \mathfrc{s}} \left( \dfrac{1-\pi_k}{\sum_{l \in \mathfrc{s}}(1-\pi_l)} \right)^2 \right] \eqname{[Deville, 1999]} \,{.}
\end{align*}
}\onslide*<3>{
An approximation that is implement with the \texttt{survey} package was published by Brewer (2002)
\begin{equation*}
	\Vest{\hat{\tau}_{\pi}}_{\text{brewer}} = \sum_{k \in \mathfrc{s}}\left(
\dfrac{1}{b_k^{\ast}} - \pi_k \right)  \left( \dfrac{y_k}{\pi_k} -
\dfrac{\hat{\tau}_{\pi}}{n} \right)^2\;{,}
\end{equation*}
Brewer (2002) presents the following (among others) choices for $ b_k^{\ast}$
\begin{align*}
	{}_{1}\hat{b}_k^{\ast} = & \dfrac{n -1 }{n - \pi_k}\;{,} \\
  {}_{2}\hat{b}_k^{\ast} = & \dfrac{n -1 }{n - n^{-1} \sum_{k \in \mathcal{U}} \pi_k^2} \;{.}
\end{align*}
Not that ${}_{2}\hat{b}_k^{\ast}$ includes a statistic based on the whole population.
The version with ${}_{1}\hat{b}_k^{\ast}$ is implement with the \texttt{survey} package.
}
\end{frame}


\begin{frame}[fragile]{Design Based Variance Estimation}
\begin{lrbox}{\mysavebox}
 <<ExPPSVest.prep,echo=1:34,cache=TRUE>>=
library(sampling)
library(survey)
data(belgianmunicipalities)  #load the population
DATA    <- belgianmunicipalities[-2,] #we remove a very large municipality
n       <- 25                #a 4.3% sample
DATA$IP <- inclusionprobabilities(DATA$Tot03,n)
##compute the joint inclusion probabilities (for Sampford sampling)
IPkl    <- UPsampfordpi2(DATA$IP) #this can take some seconds 
##Covariance matrix of the sample indicator
DELTA   <- IPkl - DATA$IP%*%t(DATA$IP) 
##The tue variance is
V <- with( DATA ,t(cbind(Men04/IP))%*%DELTA%*%(cbind(Men04/IP)) )
sqrt(V)
@
\end{lrbox}
\onslide*<1>{We want to estimate the total number of men in 2004 in Belgium by sampling municipalities
proportional to their total population in 2003.
\usebox{\mysavebox}}
\begin{lrbox}{\mysavebox}
<<ExPPSVest.sam,echo=1:18,tidy=TRUE>>=
library(Matrix)  #needed for 'svydesign' objects with 'pps=ppsmat()'
set.seed(5675)
##select a sampling using the Sampford's method
s <- UPsampford(DATA$IP) 
DATA.s <- DATA[s==1,]
IPkl.s <- IPkl[s==1,s==1]
## Variances without replacement:
## Vest_1
dpps_br <- svydesign(id=~1,  fpc=~IP, data=DATA.s, pps="brewer")
dpps_ht <- svydesign(id=~1,  fpc=~IP, data=DATA.s,pps=ppsmat(IPkl.s))
## Vest_2
dpps_yg  <- svydesign(id=~1,  fpc=~IP, data=DATA.s,pps=ppsmat(IPkl.s),variance="YG")
## The with replacement approximation
dpps_wr <-svydesign(id=~1, probs=~IP, data=DATA.s)
##Estimation: 
V_1<-svytotal(~Men04, dpps_ht)
V_2<-svytotal(~Men04, dpps_yg)
br<-svytotal(~Men04, dpps_br)
wr<-svytotal(~Men04, dpps_wr)

se <- sqrt(V)
Vest <- 
rbind("$\\Vest{\\hat{\\tau}_{\\pi}}_1$"=c(V_1,se=SE(V_1),rel.er=SE(V_1)/sqrt(V)-1) 
     ,"$\\Vest{\\hat{\\tau}_{\\pi}}_2$"=c(V_2,se=SE(V_2),rel.er=SE(V_2)/sqrt(V)-1)
     ,"$\\Vest{\\hat{\\tau}_{\\pi}}_{\\text{brewer1}}$" =c(br,se=SE(br),rel.er=SE(br)/sqrt(V)-1)
     ,"$\\Vest{\\hat{\\tau}_{\\pi}}_{\\text{wr}}$"=c(wr,se=SE(wr),rel.er=SE(wr)/sqrt(V)-1))

@
\end{lrbox}
\onslide*<2>{ For the estimation we use the \texttt{survey} package and define \texttt{svydesign} objects with different variance estimators.
\usebox{\mysavebox} }
\onslide*<3>{
These are the results from our estimation:
<<ExPPSVest.tab,results='asis',echo=FALSE>>=
tab.vest <- xtable(Vest,digits = 2,caption = "Estimated Standard Errors and their Relative Error")
align(tab.vest) <- "r|rrr"
print(tab.vest,caption.placement = "top", sanitize.text.function=identity)
@
The variance estimate from $\Vest{\hat{\tau}_{\pi}}_1$ is way off, compared to the true value. The approximate method by Brewer $\Vest{\hat{\tau}_{\pi}}_{\text{brewer1}}$ is not much different from $\Vest{\hat{\tau}_{\pi}}_2$, which is good, considering that we didn't need the $\pi_{kl}$'s for this.
As can be expect the with replacement approximation $\Vest{\hat{\tau}_{\pi}}_{\text{wr}}$ is slightly above $\Vest{\hat{\tau}_{\pi}}_2$ and $\Vest{\hat{\tau}_{\pi}}_{\text{brewer1}}$.
}
\end{frame}

% \section{Taylor-based methods}
% 
\begin{frame}{Non-linear Statistics}
The estimator we use are often non-linear, like $\overline{y}_w$. 
Which is a problem, in particular for variance estimation. Mind that:
\begin{align*}
\E{ \dfrac{\hat{\tau}_{y_1\,w}}{\hat{\tau}_{y_2\,w}} } \approx \dfrac{\E{\hat{\tau}_{y_1\,w}}}{\E{\hat{\tau}_{y_2\,w} } }  \\
\V{ \dfrac{\hat{\tau}_{y_1\,w}}{\hat{\tau}_{y_2\,w}} } \neq \dfrac{\V{\hat{\tau}_{y_1\,w}}}{\V{\hat{\tau}_{y_2\,w} } }  
\end{align*}
\end{frame}

\begin{frame}{Taylor-linearization}
\onslide*<1>{
In case our statistic of interest $\theta$ can be displayed as a function $f$ of $Q$ totals
 $$
 \theta  = f \left( \boldsymbol{\tau} \right)\;{,}
 $$
  with $\boldsymbol{\tau} = (\tau_{x_1}{,}\,\ldots{,}\,\tau_{x_q}{,}\,\ldots{,}\,\tau_{x_Q})^\top$ and
  $\tau_{x_1} = \sum_{k \in \mathcal{U}} x_{kq}$.
  We estimate $\theta$ by 
  $$
  \hat{\theta}  = f \left( \hat{\boldsymbol{\tau}} \right) \;{,}
  $$
 with $\hat{\boldsymbol{\tau}} = (\hat\tau_{x_1}{,}\,\ldots{,}\,\hat\tau_{x_q}{,}\,\ldots{,}\,\hat\tau_{x_Q})^\top$.
}
\onslide*<2>{
If $f$ is continuously differentiable up to second order between $\boldsymbol{\tau}$ and $\hat{\boldsymbol{\tau}}$ we can use the Taylor series of estimator $\hat{\theta}$ to obtain a linearized version of it
\begin{align*}
\hat{\theta}  = \theta + \sum_{q = 1}^Q \left[ \dfrac{\partial f( t_1,\,\ldots,\,t_Q
)}{\partial t_q} \right]_{\mathbf{t}=\boldsymbol{\tau}} \left( \hat{\tau}_{x_q} - \tau_{x_q}
\right) + R(\hat{\boldsymbol{\tau}}{,}\boldsymbol{\tau})\;{,}
\end{align*}
where
\begin{align*}
R(\hat{\boldsymbol{\tau}}{,}\boldsymbol{\tau}) = \dfrac{1}{2} \sum_{q = 1}^Q \sum_{p =
1}^Q \left[  \dfrac{\partial^2 f( t_1,\,\ldots,\,t_Q)}{\partial t_{q}\partial
t_{p}}\right]_{\mathbf{t}=\ddot{\boldsymbol{\tau}}} (\hat{\tau}_{x_q} - \tau_{x_q})
(\hat{\tau}_{x_p} - \tau_{x_p})
\end{align*}
and $\ddot{\boldsymbol{\tau}}$ is between $\hat{\boldsymbol{\tau}}$ and $\boldsymbol{\tau}$.
In most application the remainder term $R$ is ignored for large enough sample sizes.
}
\onslide*<3>{
Thus we can approximate the variance of $\hat{\theta}$ by
\begin{align*}
\V{\hat{\theta}}  & \approx  \V{ \sum_{q = 1}^Q \left[
\dfrac{\partial f( t_1,\,\ldots,\,t_Q )}{\partial t_q}
\right]_{\mathbf{t}=\boldsymbol{\tau} } \hat{\tau}_{x_q} }  \\
  & = \sum_{q = 1}^Q  a_q^2  \V{\hat{\tau}_{x_q}} + 2 \sum_{q=1}^{Q}  
  \sum_{\substack{ p = 1 \\ p < q }}^{Q} a_q a_p \COV{\hat{\tau}_{x_q}}{\hat{\tau}_{x_p}} \;{,} \nonumber
\end{align*}
 with $a_q = [ \frac{\partial f( t_1,\,\ldots,\,t_Q )}{\partial t_q} ]_{\mathbf{t}=\boldsymbol{\tau}}$.
}
\onslide*<4>{
For $\hat{\boldsymbol{\tau}} =  (\hat\tau_{x_1\,w}{,}\,\ldots{,}\,\hat\tau_{x_q\,w}{,}\,\ldots{,}\,\hat\tau_{x_Q\,w})^\top$
 Woodruff (1971) proposes the transformation of $x_{kq}$
 \begin{align*}
 z_k = \sum_{q = 1}^Q  a_q x_{kq} 
 \end{align*}
 and use the following expression as an approximate variance of $\hat\theta$
 \begin{align*}
 \V{\hat{\theta}} \approx \V{ \sum_{k \in \mathfrc{s}} w_k z_k }\;{.}
 \end{align*}  
 This approximation is far more convenient to estimate then to estimate all the different variances and covariance in the above formula separately. $z_k$ is also sometimes called the linearized variable.
}
\end{frame}

\begin{frame}{Example Taylor-linearization}
\onslide*<1>{
Suppose we want to estimate $\theta = \frac{\tau_y}{N}$ the population mean of variable $\mathcal{Y}$.
To do this we use estimator $\overline{y}_w=\overline{y}_\pi$, i.e. we set $w_k = d_k$ for all $k \in \mathfrc{s}$. 
 Now we have
 $$\hat\theta = f \left( \boldsymbol{\tau} \right) = f \left( (\hat{\tau}_{y,\pi},\hat{\tau}_{x,\pi} ) \right) = \dfrac{\hat{\tau}_{y,\pi}}{\hat{\tau}_{x,\pi}}\;,$$
 were $\hat{\tau}_{y,\pi} = \sum_{k \in \mathfrc{s}} d_k y_k$ and  $\hat{\tau}_{x,\pi}=\sum_{k \in \mathfrc{s}} d_k$, because $x_k=1$ for all $k \in \mathcal{U}$. Our estimator is a function of Q=2 totals, and we have
 \begin{align*}
 a_1 &= \dfrac{1}{\tau_{x}} & a_2 = -\dfrac{\tau_{y}}{\tau_{x}^2}= -\dfrac{\theta}{\tau_x} \\
z_k &= a_1 y_k + a_2 x_k = \dfrac{1}{\tau_{x}}\left( y_k - \theta \right) &
 \end{align*}
}\onslide*<2>{
  To estimate the approximate variance $\V{ \sum_{k \in \mathfrc{s}} d_k z_k }$ we need estimates for the $z_k$'s,  because they involve unknown statistics $\tau_{x}$ and $\theta$. 
$$\hat{z}_k =   \dfrac{1}{\hat\tau_{x,\pi}}\left(y_k - \overline{y}_\pi \right) $$
Our variance estimator would be $\Vest{ \sum_{k \in \mathfrc{s}} d_k \hat{z}_k }$
for which
$\Vest{.}_1$ or $\Vest{.}_2$ could be used or an estimator for an approximate design variance. \newline
Note that the variances of the $\hat{z}_k$'s (and the covariances between them) is often thought to be negligible and is therefore usually not considered.
}
\end{frame}


\begin{frame}{Variance Estimation for Calibration Estimators}
 The variance of $\hat{\tau}_{w}$ with GREG weights can be approximated by
$$
 \V{\hat{\tau}_{w}} \approx \V{ \sum_{k \in \mathfrc{s}} d_k e_k }\;{,}
$$
 where the $e_k$'s are the residuals of regression  $\hat{y}_k =  \mathbf{x}_k^\top \boldsymbol{\beta}$
with $$
 \boldsymbol{\beta} =   \left(\sum_{k \in \mathcal{U}} c_k \mathbf{x}_k \mathbf{x}_k^\top \right)^{-1} \left( \sum_{k \in \mathcal{U}} c_k \mathbf{x}_k  y_k \right)\;{.}
 $$
 To estimate $\V{ \sum_{k \in \mathfrc{s}} d_k e_k }$ we need to estimates $\hat{e}_k$ for the residuals $e_k$'s.
 We can obtain them using $\hat{e}_k  = y_k - \mathbf{x}_k^\top \hat{\boldsymbol{\beta}}$
 where $\hat{\boldsymbol{\beta}}$ is the vector of the estimated regression coefficients used in solving the calibration problem.

 Finally we estimate the variance of $\hat{\tau}_{w}$ by using an estimator $\Vest{ \sum_{k \in \mathfrc{s}} d_k \hat{e}_k }$ that is appropriate for the present sampling design.
\end{frame}

\begin{frame}{Variance Estimation for Calibration Estimators}
 Deville (1999) showed that for the estimation of non-linear estimator that use calibration weights, like $\overline{y}_w$ with GREG weights, the same technique can be used to obtain a variance estimator.
 Here the residuals $e_k$ are from the regression of the linearized variable $z_k$ on the auxiliary variables. 
 Then we have
 $$\Vest{ \sum_{k \in \mathfrc{s}} d_k \hat{e}_k^\ast }\;,$$
 with
 $\hat{e}_k^\ast=\hat{z}_k - \mathbf{x}_k^\top \hat{\boldsymbol{\beta}}$.
\uncover<2>{
~\\[1cm]
With raking weights variance estimation can be done in a similar way, although the used regression is different from the GREG case.}
\end{frame}

\begin{frame}[fragile]{Taylor-linearization with Calibration Weights}
<<ExPPSVestNoLin.prep,results='hide',echo=FALSE>>=
data(smho.N874)    
smho. <- smho.N874[smho.N874$hosp.type != 4, ]
smho.$hosp.type <- as.factor(smho.$hosp.type)
smho.$FINDIRCT  <- as.factor(smho.$FINDIRCT)
lmod1 <- lm(EXPTOTAL ~ SEENCNT + EOYCNT + FINDIRCT + hosp.type:BEDS, data=smho.)
tab.model <- xtable(summary(lmod1),digits = 2,caption = "Model Summary")
print(tab.model,caption.placement = "top")


smho.[,"BEDS"] <-   # before sampling order the data set by hospital type
  smho.[order(smho.$hosp.type),"BEDS"] 

x <- smho.[,"BEDS"]
x[x <= 5] <- 5      #recode small hospitals to have a minimum size
x <- sqrt(x)

n <- 80             #sample size
IP  <- n*x/sum(x)
@
\begin{lrbox}{\mysavebox}
<<ExPPSVestNoLin.calib,tidy=TRUE>>=
set.seed(428274453)
sam <- UPsampford(IP)       # now we use Sampford sampling
sam.dat    <- smho.[sam==1, ]
sam.dat$IP <- IP[sam==1]   
#1. build a 'design' object
sam.dsgn <- 
  svydesign(ids = ~1,       # no clusters
            data = sam.dat, # the sample data 
            fpc = ~IP,      # inclusion probabilities
            pps = "brewer") # handeling of 2. order inc.prob.
lmod2 <- lm(EXPTOTAL ~ SEENCNT + EOYCNT + hosp.type:BEDS, data=smho.)
pop.tots <- colSums(model.matrix(lmod2)) 
#2. use 'calibrate' to compute GREG weights
sam.cal <- 
  calibrate(design = sam.dsgn,
            formula = ~ SEENCNT + EOYCNT + hosp.type:BEDS,
            population = pop.tots,
            calfun='linear' )
@
\end{lrbox}
\onslide*<1>{Recall the calibration example to estimate total expenditures of hospitals. We know want to estimate the mean using $\overline{y}_w$
\usebox{\mysavebox}}
\begin{lrbox}{\mysavebox}
<<ExPPSVestNoLin.est,tidy=TRUE>>=
#Estimation with design weights
svymean(~EXPTOTAL,design=sam.dsgn)
#and with calibrated weights
svymean(~EXPTOTAL,design=sam.cal)
@
\end{lrbox}
\onslide*<2>{
\usebox{\mysavebox}
For \texttt{sam.cal} the reported standard errors are estimates of the linearized variance using Brewer's approximation.}
\end{frame}

 \begin{frame}
 \frametitle{Non-linear and \\ Non-differentiable Estimators}
   There are also those estimators that are non-linear and non-differentiable and thus cannot be linearized using a Taylor series.
   \begin{itemize}
    \item<2-> A prominent case are estimators for quantiles, like the median. 
    \item<3-> But also poverty measures such as the at-risk-of poverty rate and inequality measures as the GINI coefficient and the quintile share ratio.
   \end{itemize}
   \uncover<4->{
    However it is possible by using the concept of \emph{influence function} or \emph{estimation equations} to obtain a linearized variable for these estimator, too. For example, as the linearized variable of the median we could use
 $$
 z_k		 = - \dfrac{1}{N F'_N[\text{MED}(M)]} \left(\mathbbm{1}[y_k \leq \text{MED}(M)] -0{.}5 \right)\;{,}
 $$

where $\text{MED}(M)$ is the median, $F_N(y)  = \frac{\sum_{k \in \mathcal{U}} \mathbbm{1} [y_k \leq y]}{N}$ is the empirical distribution function of variable $\mathcal{Y}$ at point $y$ and $F'_N$ its first derivative.
$\mathbbm{1}[.]$ is a indicator function assuming the value of $1$ if the argument is true and $0$ otherwise.
The \texttt{svyquantile()} function from the \texttt{survey} package has such a method implemented.
}
 \end{frame}

 \begin{frame}[allowframebreaks]\frametitle{Literature}    
% %\scriptsize
  \begin{thebibliography}{10}
   \setbeamertemplate{bibliography item}[book]
  \bibitem{Brewer2002}
   K.~Brewer.
   \newblock  Combined Survey Sampling Inference.
   \newblock {\em Arnold}, 2002.
   \setbeamertemplate{bibliography item}[article]
  \bibitem{Deville1999}
  J.C.~Deville.
    \newblock  Variance Estimation for Complex Statistics and Estimators: Linearization and Eesidual Techniques.
    \newblock {\em Survey Methodology}, 1999.
  \setbeamertemplate{bibliography item}[book]
  \bibitem{Hajek1981}
   J.~H\'{a}jek.
  \newblock  Sampling from a Finite Population.
    \newblock {\em Dekker}, 1981.
  \setbeamertemplate{bibliography item}[article]
  \bibitem{MateiTille2005}
  A.~Matei, Y.~Till{\'e}.
    \newblock  Evaluation of Variance Approximations and Estimators in Maximum Entropy
Sampling with Unequal Probability and Fixed Sample Size.
    \newblock {\em Journal of Official Statistics}, 2005.
    \bibitem{Woodruff1971}
    R.S.~Woodruff.
    \newblock A Simple Method for Approximating the Variance of a Complicated Estimate.
    \newblock {\em Journal of the American Statistical Association}, 1971.
   \end{thebibliography}
\end{frame} 

\end{document}
